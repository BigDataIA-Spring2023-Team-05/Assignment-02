[2023-02-24 20:42:29,907] {processor.py:153} INFO - Started process (PID=41) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:42:29,919] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:42:29,931] {logging_mixin.py:115} INFO - [2023-02-24 20:42:29,931] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:42:30,030] {logging_mixin.py:115} INFO - [2023-02-24 20:42:30,020] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'data'
[2023-02-24 20:42:30,034] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:42:30,142] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.256 seconds
[2023-02-24 20:43:00,710] {processor.py:153} INFO - Started process (PID=96) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:43:00,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:43:00,722] {logging_mixin.py:115} INFO - [2023-02-24 20:43:00,722] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:43:00,949] {logging_mixin.py:115} INFO - [2023-02-24 20:43:00,931] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'data'
[2023-02-24 20:43:00,953] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:43:01,072] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.401 seconds
[2023-02-24 20:43:32,065] {processor.py:153} INFO - Started process (PID=149) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:43:32,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:43:32,069] {logging_mixin.py:115} INFO - [2023-02-24 20:43:32,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:43:32,119] {logging_mixin.py:115} INFO - [2023-02-24 20:43:32,113] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'data'
[2023-02-24 20:43:32,120] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:43:32,165] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.109 seconds
[2023-02-24 20:44:02,749] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:44:02,751] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:44:02,754] {logging_mixin.py:115} INFO - [2023-02-24 20:44:02,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:44:02,804] {logging_mixin.py:115} INFO - [2023-02-24 20:44:02,802] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'data'
[2023-02-24 20:44:02,805] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:44:02,841] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.100 seconds
[2023-02-24 20:44:33,107] {processor.py:153} INFO - Started process (PID=273) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:44:33,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:44:33,110] {logging_mixin.py:115} INFO - [2023-02-24 20:44:33,110] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:44:33,147] {logging_mixin.py:115} INFO - [2023-02-24 20:44:33,144] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'data'
[2023-02-24 20:44:33,148] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:44:33,197] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.101 seconds
[2023-02-24 20:44:41,167] {processor.py:153} INFO - Started process (PID=302) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:44:41,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:44:41,171] {logging_mixin.py:115} INFO - [2023-02-24 20:44:41,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:44:41,215] {logging_mixin.py:115} INFO - [2023-02-24 20:44:41,212] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from backend.data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'backend'
[2023-02-24 20:44:41,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:44:41,269] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.112 seconds
[2023-02-24 20:45:12,289] {processor.py:153} INFO - Started process (PID=364) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:45:12,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:45:12,297] {logging_mixin.py:115} INFO - [2023-02-24 20:45:12,297] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:45:12,489] {logging_mixin.py:115} INFO - [2023-02-24 20:45:12,484] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from backend.data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'backend'
[2023-02-24 20:45:12,494] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:45:12,588] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.321 seconds
[2023-02-24 20:45:43,064] {processor.py:153} INFO - Started process (PID=417) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:45:43,066] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:45:43,068] {logging_mixin.py:115} INFO - [2023-02-24 20:45:43,068] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:45:43,098] {logging_mixin.py:115} INFO - [2023-02-24 20:45:43,096] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from backend.data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'backend'
[2023-02-24 20:45:43,099] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:45:43,129] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.075 seconds
[2023-02-24 20:46:13,972] {processor.py:153} INFO - Started process (PID=479) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:46:13,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:46:13,975] {logging_mixin.py:115} INFO - [2023-02-24 20:46:13,975] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:46:13,999] {logging_mixin.py:115} INFO - [2023-02-24 20:46:13,997] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from backend.data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'backend'
[2023-02-24 20:46:13,999] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:46:14,040] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.074 seconds
[2023-02-24 20:46:44,632] {processor.py:153} INFO - Started process (PID=532) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:46:44,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:46:44,635] {logging_mixin.py:115} INFO - [2023-02-24 20:46:44,635] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:46:44,663] {logging_mixin.py:115} INFO - [2023-02-24 20:46:44,661] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from backend.data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'backend'
[2023-02-24 20:46:44,665] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:46:44,700] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.077 seconds
[2023-02-24 20:47:16,037] {processor.py:153} INFO - Started process (PID=594) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:47:16,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:47:16,040] {logging_mixin.py:115} INFO - [2023-02-24 20:47:16,040] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:47:16,083] {logging_mixin.py:115} INFO - [2023-02-24 20:47:16,079] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from backend.data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'backend'
[2023-02-24 20:47:16,084] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:47:16,140] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.117 seconds
[2023-02-24 20:47:46,596] {processor.py:153} INFO - Started process (PID=642) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:47:46,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:47:46,601] {logging_mixin.py:115} INFO - [2023-02-24 20:47:46,601] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:47:46,621] {logging_mixin.py:115} INFO - [2023-02-24 20:47:46,619] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from backend.data.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'backend'
[2023-02-24 20:47:46,622] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:47:46,672] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.086 seconds
[2023-02-24 20:47:54,188] {processor.py:153} INFO - Started process (PID=655) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:47:54,190] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:47:54,191] {logging_mixin.py:115} INFO - [2023-02-24 20:47:54,191] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:47:54,216] {logging_mixin.py:115} INFO - [2023-02-24 20:47:54,214] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from airflow.plugins.sql_aws_metadata import aws_extract_data_to_sqlite
ModuleNotFoundError: No module named 'airflow.plugins'
[2023-02-24 20:47:54,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:47:54,260] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.080 seconds
[2023-02-24 20:48:18,041] {processor.py:153} INFO - Started process (PID=705) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:48:18,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:48:18,044] {logging_mixin.py:115} INFO - [2023-02-24 20:48:18,044] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:48:18,081] {logging_mixin.py:115} INFO - [2023-02-24 20:48:18,076] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 5, in <module>
    from awscloud.s3 import main as s3_package
ModuleNotFoundError: No module named 'awscloud'
[2023-02-24 20:48:18,082] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:48:18,110] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.076 seconds
[2023-02-24 20:48:48,408] {processor.py:153} INFO - Started process (PID=758) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:48:48,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:48:48,410] {logging_mixin.py:115} INFO - [2023-02-24 20:48:48,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:48:48,437] {logging_mixin.py:115} INFO - [2023-02-24 20:48:48,431] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 5, in <module>
    from awscloud.s3 import main as s3_package
ModuleNotFoundError: No module named 'awscloud'
[2023-02-24 20:48:48,438] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:48:48,482] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.080 seconds
[2023-02-24 20:49:19,207] {processor.py:153} INFO - Started process (PID=819) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:49:19,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:49:19,210] {logging_mixin.py:115} INFO - [2023-02-24 20:49:19,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:49:19,235] {logging_mixin.py:115} INFO - [2023-02-24 20:49:19,231] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 5, in <module>
    from awscloud.s3 import main as s3_package
ModuleNotFoundError: No module named 'awscloud'
[2023-02-24 20:49:19,237] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:49:19,260] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.059 seconds
[2023-02-24 20:49:50,158] {processor.py:153} INFO - Started process (PID=882) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:49:50,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:49:50,162] {logging_mixin.py:115} INFO - [2023-02-24 20:49:50,162] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:49:50,215] {logging_mixin.py:115} INFO - [2023-02-24 20:49:50,200] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 5, in <module>
    from awscloud.s3 import main as s3_package
ModuleNotFoundError: No module named 'awscloud'
[2023-02-24 20:49:50,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:49:50,302] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.157 seconds
[2023-02-24 20:50:20,950] {processor.py:153} INFO - Started process (PID=935) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:50:20,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:50:20,954] {logging_mixin.py:115} INFO - [2023-02-24 20:50:20,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:50:20,983] {logging_mixin.py:115} INFO - [2023-02-24 20:50:20,978] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 5, in <module>
    from awscloud.s3 import main as s3_package
ModuleNotFoundError: No module named 'awscloud'
[2023-02-24 20:50:20,984] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:50:21,011] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.069 seconds
[2023-02-24 20:50:51,357] {processor.py:153} INFO - Started process (PID=996) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:50:51,361] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:50:51,367] {logging_mixin.py:115} INFO - [2023-02-24 20:50:51,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:50:53,252] {logging_mixin.py:115} INFO - [2023-02-24 20:50:53,248] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 20:50:53,253] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:50:53,279] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.933 seconds
[2023-02-24 20:51:24,134] {processor.py:153} INFO - Started process (PID=1056) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:51:24,137] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:51:24,138] {logging_mixin.py:115} INFO - [2023-02-24 20:51:24,138] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:51:24,876] {logging_mixin.py:115} INFO - [2023-02-24 20:51:24,874] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 20:51:24,877] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:51:24,898] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.769 seconds
[2023-02-24 20:51:55,221] {processor.py:153} INFO - Started process (PID=1124) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:51:55,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:51:55,226] {logging_mixin.py:115} INFO - [2023-02-24 20:51:55,226] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:51:56,294] {logging_mixin.py:115} INFO - [2023-02-24 20:51:56,293] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 20:51:56,296] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:51:56,321] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.109 seconds
[2023-02-24 20:52:26,704] {processor.py:153} INFO - Started process (PID=1194) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:52:26,705] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:52:26,706] {logging_mixin.py:115} INFO - [2023-02-24 20:52:26,706] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:52:27,169] {logging_mixin.py:115} INFO - [2023-02-24 20:52:27,165] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:52:27,170] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:52:27,200] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.500 seconds
[2023-02-24 20:52:57,447] {processor.py:153} INFO - Started process (PID=1251) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:52:57,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:52:57,463] {logging_mixin.py:115} INFO - [2023-02-24 20:52:57,463] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:52:58,597] {logging_mixin.py:115} INFO - [2023-02-24 20:52:58,591] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:52:58,599] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:52:58,661] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.229 seconds
[2023-02-24 20:53:29,024] {processor.py:153} INFO - Started process (PID=1317) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:53:29,027] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:53:29,028] {logging_mixin.py:115} INFO - [2023-02-24 20:53:29,028] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:53:29,615] {logging_mixin.py:115} INFO - [2023-02-24 20:53:29,611] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:53:29,616] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:53:29,642] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.624 seconds
[2023-02-24 20:54:00,401] {processor.py:153} INFO - Started process (PID=1383) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:54:00,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:54:00,403] {logging_mixin.py:115} INFO - [2023-02-24 20:54:00,403] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:54:01,152] {logging_mixin.py:115} INFO - [2023-02-24 20:54:01,144] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:54:01,154] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:54:01,187] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.790 seconds
[2023-02-24 20:56:28,773] {processor.py:153} INFO - Started process (PID=43) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:56:28,780] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:56:28,783] {logging_mixin.py:115} INFO - [2023-02-24 20:56:28,783] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:56:34,520] {logging_mixin.py:115} INFO - [2023-02-24 20:56:34,458] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:56:34,526] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:56:35,001] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.253 seconds
[2023-02-24 20:57:12,074] {processor.py:153} INFO - Started process (PID=100) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:57:12,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:57:12,077] {logging_mixin.py:115} INFO - [2023-02-24 20:57:12,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:57:12,629] {logging_mixin.py:115} INFO - [2023-02-24 20:57:12,623] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:57:12,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:57:12,659] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.589 seconds
[2023-02-24 20:57:43,562] {processor.py:153} INFO - Started process (PID=167) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:57:43,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:57:43,565] {logging_mixin.py:115} INFO - [2023-02-24 20:57:43,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:57:43,983] {logging_mixin.py:115} INFO - [2023-02-24 20:57:43,979] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:57:43,984] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:57:44,005] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.450 seconds
[2023-02-24 20:58:14,787] {processor.py:153} INFO - Started process (PID=224) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:58:14,791] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:58:14,792] {logging_mixin.py:115} INFO - [2023-02-24 20:58:14,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:58:15,936] {logging_mixin.py:115} INFO - [2023-02-24 20:58:15,924] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:58:15,937] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:58:16,039] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.260 seconds
[2023-02-24 20:58:47,712] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:58:47,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:58:47,715] {logging_mixin.py:115} INFO - [2023-02-24 20:58:47,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:58:48,471] {logging_mixin.py:115} INFO - [2023-02-24 20:58:48,467] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:58:48,473] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:58:48,520] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.813 seconds
[2023-02-24 20:59:20,263] {processor.py:153} INFO - Started process (PID=347) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:59:20,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:59:20,266] {logging_mixin.py:115} INFO - [2023-02-24 20:59:20,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:59:20,726] {logging_mixin.py:115} INFO - [2023-02-24 20:59:20,722] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:59:20,728] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:59:20,755] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.497 seconds
[2023-02-24 20:59:51,096] {processor.py:153} INFO - Started process (PID=414) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 20:59:51,098] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 20:59:51,099] {logging_mixin.py:115} INFO - [2023-02-24 20:59:51,098] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:59:51,823] {logging_mixin.py:115} INFO - [2023-02-24 20:59:51,815] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 20:59:51,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 20:59:51,873] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.780 seconds
[2023-02-24 21:00:22,179] {processor.py:153} INFO - Started process (PID=479) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:00:22,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:00:22,189] {logging_mixin.py:115} INFO - [2023-02-24 21:00:22,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:00:23,022] {logging_mixin.py:115} INFO - [2023-02-24 21:00:23,018] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 9, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2023-02-24 21:00:23,024] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:00:23,061] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.911 seconds
[2023-02-24 21:10:15,931] {processor.py:153} INFO - Started process (PID=44) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:10:15,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:10:15,937] {logging_mixin.py:115} INFO - [2023-02-24 21:10:15,936] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:10:23,386] {logging_mixin.py:115} INFO - [2023-02-24 21:10:23,326] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:10:23,409] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:10:23,701] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 7.778 seconds
[2023-02-24 21:10:55,084] {processor.py:153} INFO - Started process (PID=112) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:10:55,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:10:55,096] {logging_mixin.py:115} INFO - [2023-02-24 21:10:55,096] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:11:00,084] {logging_mixin.py:115} INFO - [2023-02-24 21:11:00,077] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:11:00,090] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:11:00,201] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.139 seconds
[2023-02-24 21:11:31,325] {processor.py:153} INFO - Started process (PID=178) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:11:31,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:11:31,329] {logging_mixin.py:115} INFO - [2023-02-24 21:11:31,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:11:34,443] {logging_mixin.py:115} INFO - [2023-02-24 21:11:34,440] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:11:34,451] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:11:34,512] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.193 seconds
[2023-02-24 21:12:04,736] {processor.py:153} INFO - Started process (PID=239) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:12:04,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:12:04,740] {logging_mixin.py:115} INFO - [2023-02-24 21:12:04,740] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:12:07,956] {logging_mixin.py:115} INFO - [2023-02-24 21:12:07,953] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:12:07,960] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:12:08,048] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.318 seconds
[2023-02-24 21:12:39,176] {processor.py:153} INFO - Started process (PID=306) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:12:39,178] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:12:39,180] {logging_mixin.py:115} INFO - [2023-02-24 21:12:39,180] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:12:42,245] {logging_mixin.py:115} INFO - [2023-02-24 21:12:42,244] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:12:42,248] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:12:42,308] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.139 seconds
[2023-02-24 21:13:12,512] {processor.py:153} INFO - Started process (PID=370) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:13:12,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:13:12,516] {logging_mixin.py:115} INFO - [2023-02-24 21:13:12,516] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:13:15,639] {logging_mixin.py:115} INFO - [2023-02-24 21:13:15,637] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:13:15,642] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:13:15,680] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.176 seconds
[2023-02-24 21:13:46,163] {processor.py:153} INFO - Started process (PID=437) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:13:46,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:13:46,167] {logging_mixin.py:115} INFO - [2023-02-24 21:13:46,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:13:49,169] {logging_mixin.py:115} INFO - [2023-02-24 21:13:49,168] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:13:49,172] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:13:49,251] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.094 seconds
[2023-02-24 21:14:20,146] {processor.py:153} INFO - Started process (PID=504) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:14:20,151] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:14:20,155] {logging_mixin.py:115} INFO - [2023-02-24 21:14:20,154] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:14:23,553] {logging_mixin.py:115} INFO - [2023-02-24 21:14:23,552] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:14:23,573] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:14:23,615] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.487 seconds
[2023-02-24 21:14:54,571] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:14:54,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:14:54,575] {logging_mixin.py:115} INFO - [2023-02-24 21:14:54,575] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:14:57,460] {logging_mixin.py:115} INFO - [2023-02-24 21:14:57,459] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:14:57,462] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:14:57,510] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.947 seconds
[2023-02-24 21:15:27,797] {processor.py:153} INFO - Started process (PID=636) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:15:27,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:15:27,801] {logging_mixin.py:115} INFO - [2023-02-24 21:15:27,801] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:15:30,730] {logging_mixin.py:115} INFO - [2023-02-24 21:15:30,729] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:15:30,734] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:15:30,797] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.008 seconds
[2023-02-24 21:16:00,916] {processor.py:153} INFO - Started process (PID=703) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:16:00,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:16:00,931] {logging_mixin.py:115} INFO - [2023-02-24 21:16:00,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:16:03,794] {logging_mixin.py:115} INFO - [2023-02-24 21:16:03,793] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:16:03,795] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:16:03,825] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.917 seconds
[2023-02-24 21:16:34,822] {processor.py:153} INFO - Started process (PID=770) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:16:34,829] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:16:34,836] {logging_mixin.py:115} INFO - [2023-02-24 21:16:34,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:16:38,649] {logging_mixin.py:115} INFO - [2023-02-24 21:16:38,647] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:16:38,654] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:16:38,714] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.912 seconds
[2023-02-24 21:17:08,937] {processor.py:153} INFO - Started process (PID=827) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:17:08,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:17:08,944] {logging_mixin.py:115} INFO - [2023-02-24 21:17:08,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:17:11,882] {logging_mixin.py:115} INFO - [2023-02-24 21:17:11,881] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:17:11,885] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:17:11,914] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.985 seconds
[2023-02-24 21:17:42,606] {processor.py:153} INFO - Started process (PID=892) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:17:42,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:17:42,610] {logging_mixin.py:115} INFO - [2023-02-24 21:17:42,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:17:45,636] {logging_mixin.py:115} INFO - [2023-02-24 21:17:45,635] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:17:45,643] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:17:45,686] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.088 seconds
[2023-02-24 21:18:16,614] {processor.py:153} INFO - Started process (PID=964) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:18:16,616] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:18:16,618] {logging_mixin.py:115} INFO - [2023-02-24 21:18:16,618] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:18:19,884] {logging_mixin.py:115} INFO - [2023-02-24 21:18:19,880] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:18:19,893] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:18:20,061] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.457 seconds
[2023-02-24 21:18:50,731] {processor.py:153} INFO - Started process (PID=1030) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:18:50,732] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:18:50,734] {logging_mixin.py:115} INFO - [2023-02-24 21:18:50,734] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:18:53,775] {logging_mixin.py:115} INFO - [2023-02-24 21:18:53,773] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:18:53,778] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:18:53,816] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.091 seconds
[2023-02-24 21:19:24,709] {processor.py:153} INFO - Started process (PID=1095) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:19:24,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:19:24,713] {logging_mixin.py:115} INFO - [2023-02-24 21:19:24,713] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:19:27,663] {logging_mixin.py:115} INFO - [2023-02-24 21:19:27,662] {dagbag.py:412} ERROR - Failed to bag_dag: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 173, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 166, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 774, in expand
    return cls._expand(expr_format, hash_id=hash_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/croniter/croniter.py", line 620, in _expand
    raise CroniterBadCronError(cls.bad_length)
croniter.croniter.CroniterBadCronError: Exactly 5 or 6 columns has to be specified for iterator expression.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 405, in _process_modules
    dag.timetable.validate()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/timetables/interval.py", line 175, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: Exactly 5 or 6 columns has to be specified for iterator expression.
[2023-02-24 21:19:27,665] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:19:27,733] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.028 seconds
[2023-02-24 21:19:43,476] {processor.py:153} INFO - Started process (PID=1137) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:19:43,478] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:19:43,479] {logging_mixin.py:115} INFO - [2023-02-24 21:19:43,479] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:19:44,346] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:19:44,449] {logging_mixin.py:115} INFO - [2023-02-24 21:19:44,449] {manager.py:508} INFO - Created Permission View: can read on DAG:aws_extract_dag
[2023-02-24 21:19:44,458] {logging_mixin.py:115} INFO - [2023-02-24 21:19:44,458] {manager.py:508} INFO - Created Permission View: can delete on DAG:aws_extract_dag
[2023-02-24 21:19:44,464] {logging_mixin.py:115} INFO - [2023-02-24 21:19:44,463] {manager.py:508} INFO - Created Permission View: can edit on DAG:aws_extract_dag
[2023-02-24 21:19:44,465] {logging_mixin.py:115} INFO - [2023-02-24 21:19:44,464] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:19:44,472] {logging_mixin.py:115} INFO - [2023-02-24 21:19:44,472] {dag.py:2390} INFO - Creating ORM DAG for aws_extract_dag
[2023-02-24 21:19:44,484] {logging_mixin.py:115} INFO - [2023-02-24 21:19:44,484] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T04:05:00+00:00, run_after=2023-02-25T04:05:00+00:00
[2023-02-24 21:19:44,498] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.031 seconds
[2023-02-24 21:20:15,143] {processor.py:153} INFO - Started process (PID=1203) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:20:15,144] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:20:15,146] {logging_mixin.py:115} INFO - [2023-02-24 21:20:15,146] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:20:15,947] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:20:15,974] {logging_mixin.py:115} INFO - [2023-02-24 21:20:15,974] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:20:15,994] {logging_mixin.py:115} INFO - [2023-02-24 21:20:15,994] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T04:05:00+00:00, run_after=2023-02-25T04:05:00+00:00
[2023-02-24 21:20:16,003] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.866 seconds
[2023-02-24 21:20:46,456] {processor.py:153} INFO - Started process (PID=1267) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:20:46,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:20:46,459] {logging_mixin.py:115} INFO - [2023-02-24 21:20:46,459] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:20:47,141] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:20:47,163] {logging_mixin.py:115} INFO - [2023-02-24 21:20:47,162] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:20:47,179] {logging_mixin.py:115} INFO - [2023-02-24 21:20:47,179] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T04:05:00+00:00, run_after=2023-02-25T04:05:00+00:00
[2023-02-24 21:20:47,187] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.737 seconds
[2023-02-24 21:21:17,408] {processor.py:153} INFO - Started process (PID=1334) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:21:17,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:21:17,429] {logging_mixin.py:115} INFO - [2023-02-24 21:21:17,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:21:18,670] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:21:18,690] {logging_mixin.py:115} INFO - [2023-02-24 21:21:18,690] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:21:18,709] {logging_mixin.py:115} INFO - [2023-02-24 21:21:18,708] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T04:05:00+00:00, run_after=2023-02-25T04:05:00+00:00
[2023-02-24 21:21:18,717] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.339 seconds
[2023-02-24 21:21:49,217] {processor.py:153} INFO - Started process (PID=1394) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:21:49,221] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:21:49,223] {logging_mixin.py:115} INFO - [2023-02-24 21:21:49,223] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:21:50,443] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:21:50,470] {logging_mixin.py:115} INFO - [2023-02-24 21:21:50,470] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:21:50,490] {logging_mixin.py:115} INFO - [2023-02-24 21:21:50,490] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T04:05:00+00:00, run_after=2023-02-25T04:05:00+00:00
[2023-02-24 21:21:50,499] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.288 seconds
[2023-02-24 21:22:21,944] {processor.py:153} INFO - Started process (PID=1458) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:21,946] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:22:21,946] {logging_mixin.py:115} INFO - [2023-02-24 21:22:21,946] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:22,894] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:22,923] {logging_mixin.py:115} INFO - [2023-02-24 21:22:22,923] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:22:22,942] {logging_mixin.py:115} INFO - [2023-02-24 21:22:22,942] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T04:05:00+00:00, run_after=2023-02-25T04:05:00+00:00
[2023-02-24 21:22:22,951] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.013 seconds
[2023-02-24 21:22:24,033] {processor.py:153} INFO - Started process (PID=1465) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:24,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:22:24,035] {logging_mixin.py:115} INFO - [2023-02-24 21:22:24,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:25,056] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:25,141] {logging_mixin.py:115} INFO - [2023-02-24 21:22:25,141] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:22:25,162] {logging_mixin.py:115} INFO - [2023-02-24 21:22:25,162] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:15:00+00:00, run_after=2023-02-24T21:20:00+00:00
[2023-02-24 21:22:25,183] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.158 seconds
[2023-02-24 21:22:26,064] {processor.py:153} INFO - Started process (PID=1467) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:26,066] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:22:26,067] {logging_mixin.py:115} INFO - [2023-02-24 21:22:26,067] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:26,806] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:26,830] {logging_mixin.py:115} INFO - [2023-02-24 21:22:26,830] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:22:26,848] {logging_mixin.py:115} INFO - [2023-02-24 21:22:26,848] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:15:00+00:00, run_after=2023-02-24T21:20:00+00:00
[2023-02-24 21:22:26,859] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.802 seconds
[2023-02-24 21:22:57,404] {processor.py:153} INFO - Started process (PID=1534) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:57,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:22:57,407] {logging_mixin.py:115} INFO - [2023-02-24 21:22:57,407] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:58,346] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:22:58,387] {logging_mixin.py:115} INFO - [2023-02-24 21:22:58,387] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:22:58,407] {logging_mixin.py:115} INFO - [2023-02-24 21:22:58,407] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:15:00+00:00, run_after=2023-02-24T21:20:00+00:00
[2023-02-24 21:22:58,416] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.020 seconds
[2023-02-24 21:23:28,642] {processor.py:153} INFO - Started process (PID=1591) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:23:28,645] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:23:28,647] {logging_mixin.py:115} INFO - [2023-02-24 21:23:28,646] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:23:29,192] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:23:29,214] {logging_mixin.py:115} INFO - [2023-02-24 21:23:29,214] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:23:29,231] {logging_mixin.py:115} INFO - [2023-02-24 21:23:29,231] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:15:00+00:00, run_after=2023-02-24T21:20:00+00:00
[2023-02-24 21:23:29,239] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.606 seconds
[2023-02-24 21:24:00,938] {processor.py:153} INFO - Started process (PID=1658) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:24:00,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:24:00,940] {logging_mixin.py:115} INFO - [2023-02-24 21:24:00,940] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:24:01,896] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:24:02,033] {logging_mixin.py:115} INFO - [2023-02-24 21:24:02,032] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:24:02,071] {logging_mixin.py:115} INFO - [2023-02-24 21:24:02,071] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:15:00+00:00, run_after=2023-02-24T21:20:00+00:00
[2023-02-24 21:24:02,087] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.153 seconds
[2023-02-24 21:24:32,722] {processor.py:153} INFO - Started process (PID=1723) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:24:32,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:24:32,726] {logging_mixin.py:115} INFO - [2023-02-24 21:24:32,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:24:34,342] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:24:34,369] {logging_mixin.py:115} INFO - [2023-02-24 21:24:34,368] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:24:34,403] {logging_mixin.py:115} INFO - [2023-02-24 21:24:34,403] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:15:00+00:00, run_after=2023-02-24T21:20:00+00:00
[2023-02-24 21:24:34,417] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.702 seconds
[2023-02-24 21:25:04,904] {processor.py:153} INFO - Started process (PID=1787) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:25:04,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:25:04,931] {logging_mixin.py:115} INFO - [2023-02-24 21:25:04,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:25:07,162] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:25:07,226] {logging_mixin.py:115} INFO - [2023-02-24 21:25:07,225] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:25:07,257] {logging_mixin.py:115} INFO - [2023-02-24 21:25:07,257] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:20:00+00:00, run_after=2023-02-24T21:25:00+00:00
[2023-02-24 21:25:07,272] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.377 seconds
[2023-02-24 21:25:38,276] {processor.py:153} INFO - Started process (PID=1846) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:25:38,279] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:25:38,281] {logging_mixin.py:115} INFO - [2023-02-24 21:25:38,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:25:41,611] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:25:41,636] {logging_mixin.py:115} INFO - [2023-02-24 21:25:41,636] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:25:41,653] {logging_mixin.py:115} INFO - [2023-02-24 21:25:41,653] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:20:00+00:00, run_after=2023-02-24T21:25:00+00:00
[2023-02-24 21:25:41,661] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.392 seconds
[2023-02-24 21:26:12,336] {processor.py:153} INFO - Started process (PID=1914) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:26:12,338] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:26:12,340] {logging_mixin.py:115} INFO - [2023-02-24 21:26:12,340] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:26:15,861] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:26:15,977] {logging_mixin.py:115} INFO - [2023-02-24 21:26:15,976] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:26:16,037] {logging_mixin.py:115} INFO - [2023-02-24 21:26:16,037] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:20:00+00:00, run_after=2023-02-24T21:25:00+00:00
[2023-02-24 21:26:16,059] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.728 seconds
[2023-02-24 21:26:47,035] {processor.py:153} INFO - Started process (PID=1979) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:26:47,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:26:47,046] {logging_mixin.py:115} INFO - [2023-02-24 21:26:47,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:26:50,542] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:26:50,753] {logging_mixin.py:115} INFO - [2023-02-24 21:26:50,746] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:26:50,812] {logging_mixin.py:115} INFO - [2023-02-24 21:26:50,812] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:20:00+00:00, run_after=2023-02-24T21:25:00+00:00
[2023-02-24 21:26:50,835] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.825 seconds
[2023-02-24 21:27:21,250] {processor.py:153} INFO - Started process (PID=2045) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:27:21,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:27:21,254] {logging_mixin.py:115} INFO - [2023-02-24 21:27:21,254] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:27:24,680] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:27:24,741] {logging_mixin.py:115} INFO - [2023-02-24 21:27:24,741] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:27:24,765] {logging_mixin.py:115} INFO - [2023-02-24 21:27:24,765] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:20:00+00:00, run_after=2023-02-24T21:25:00+00:00
[2023-02-24 21:27:24,776] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.537 seconds
[2023-02-24 21:27:55,453] {processor.py:153} INFO - Started process (PID=2111) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:27:55,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:27:55,463] {logging_mixin.py:115} INFO - [2023-02-24 21:27:55,462] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:27:58,732] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:27:58,756] {logging_mixin.py:115} INFO - [2023-02-24 21:27:58,756] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:27:58,774] {logging_mixin.py:115} INFO - [2023-02-24 21:27:58,774] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:20:00+00:00, run_after=2023-02-24T21:25:00+00:00
[2023-02-24 21:27:58,783] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.344 seconds
[2023-02-24 21:28:29,437] {processor.py:153} INFO - Started process (PID=2177) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:28:29,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:28:29,441] {logging_mixin.py:115} INFO - [2023-02-24 21:28:29,441] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:28:33,355] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:28:33,394] {logging_mixin.py:115} INFO - [2023-02-24 21:28:33,393] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:28:33,423] {logging_mixin.py:115} INFO - [2023-02-24 21:28:33,423] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:20:00+00:00, run_after=2023-02-24T21:25:00+00:00
[2023-02-24 21:28:33,457] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.028 seconds
[2023-02-24 21:29:03,780] {processor.py:153} INFO - Started process (PID=2235) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:29:03,785] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:29:03,789] {logging_mixin.py:115} INFO - [2023-02-24 21:29:03,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:29:07,183] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:29:07,232] {logging_mixin.py:115} INFO - [2023-02-24 21:29:07,232] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:29:07,262] {logging_mixin.py:115} INFO - [2023-02-24 21:29:07,262] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:20:00+00:00, run_after=2023-02-24T21:25:00+00:00
[2023-02-24 21:29:07,276] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.531 seconds
[2023-02-24 21:29:38,249] {processor.py:153} INFO - Started process (PID=2302) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:29:38,251] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:29:38,253] {logging_mixin.py:115} INFO - [2023-02-24 21:29:38,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:29:42,702] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:29:42,744] {logging_mixin.py:115} INFO - [2023-02-24 21:29:42,743] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:29:42,784] {logging_mixin.py:115} INFO - [2023-02-24 21:29:42,784] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:25:00+00:00, run_after=2023-02-24T21:30:00+00:00
[2023-02-24 21:29:42,799] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.556 seconds
[2023-02-24 21:30:12,953] {processor.py:153} INFO - Started process (PID=2365) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:30:12,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:30:12,955] {logging_mixin.py:115} INFO - [2023-02-24 21:30:12,955] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:30:13,461] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:30:13,483] {logging_mixin.py:115} INFO - [2023-02-24 21:30:13,482] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:30:13,500] {logging_mixin.py:115} INFO - [2023-02-24 21:30:13,500] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:30:00+00:00, run_after=2023-02-24T21:35:00+00:00
[2023-02-24 21:30:13,508] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.559 seconds
[2023-02-24 21:30:44,049] {processor.py:153} INFO - Started process (PID=2433) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:30:44,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:30:44,054] {logging_mixin.py:115} INFO - [2023-02-24 21:30:44,054] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:30:46,137] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:30:46,165] {logging_mixin.py:115} INFO - [2023-02-24 21:30:46,164] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:30:46,207] {logging_mixin.py:115} INFO - [2023-02-24 21:30:46,207] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:30:00+00:00, run_after=2023-02-24T21:35:00+00:00
[2023-02-24 21:30:46,222] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.178 seconds
[2023-02-24 21:31:17,149] {processor.py:153} INFO - Started process (PID=2499) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:31:17,151] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:31:17,152] {logging_mixin.py:115} INFO - [2023-02-24 21:31:17,152] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:31:19,872] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:31:19,905] {logging_mixin.py:115} INFO - [2023-02-24 21:31:19,904] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:31:19,933] {logging_mixin.py:115} INFO - [2023-02-24 21:31:19,933] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:30:00+00:00, run_after=2023-02-24T21:35:00+00:00
[2023-02-24 21:31:19,946] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.804 seconds
[2023-02-24 21:31:51,013] {processor.py:153} INFO - Started process (PID=2565) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:31:51,015] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:31:51,017] {logging_mixin.py:115} INFO - [2023-02-24 21:31:51,017] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:31:53,758] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:31:53,788] {logging_mixin.py:115} INFO - [2023-02-24 21:31:53,788] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:31:53,809] {logging_mixin.py:115} INFO - [2023-02-24 21:31:53,809] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:30:00+00:00, run_after=2023-02-24T21:35:00+00:00
[2023-02-24 21:31:53,818] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.811 seconds
[2023-02-24 21:32:24,585] {processor.py:153} INFO - Started process (PID=2633) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:32:24,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:32:24,588] {logging_mixin.py:115} INFO - [2023-02-24 21:32:24,588] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:32:27,420] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:32:27,442] {logging_mixin.py:115} INFO - [2023-02-24 21:32:27,442] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:32:27,460] {logging_mixin.py:115} INFO - [2023-02-24 21:32:27,460] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:30:00+00:00, run_after=2023-02-24T21:35:00+00:00
[2023-02-24 21:32:27,468] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.890 seconds
[2023-02-24 21:32:57,651] {processor.py:153} INFO - Started process (PID=2700) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:32:57,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:32:57,654] {logging_mixin.py:115} INFO - [2023-02-24 21:32:57,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:33:00,622] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:33:00,692] {logging_mixin.py:115} INFO - [2023-02-24 21:33:00,691] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:33:00,718] {logging_mixin.py:115} INFO - [2023-02-24 21:33:00,718] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:30:00+00:00, run_after=2023-02-24T21:35:00+00:00
[2023-02-24 21:33:00,733] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.086 seconds
[2023-02-24 21:33:31,482] {processor.py:153} INFO - Started process (PID=2765) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:33:31,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:33:31,488] {logging_mixin.py:115} INFO - [2023-02-24 21:33:31,487] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:33:36,027] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:33:36,114] {logging_mixin.py:115} INFO - [2023-02-24 21:33:36,112] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:33:36,177] {logging_mixin.py:115} INFO - [2023-02-24 21:33:36,177] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:30:00+00:00, run_after=2023-02-24T21:35:00+00:00
[2023-02-24 21:33:36,217] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.747 seconds
[2023-02-24 21:34:06,953] {processor.py:153} INFO - Started process (PID=2831) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:34:06,965] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:34:06,973] {logging_mixin.py:115} INFO - [2023-02-24 21:34:06,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:34:10,248] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:34:10,420] {logging_mixin.py:115} INFO - [2023-02-24 21:34:10,419] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:34:10,513] {logging_mixin.py:115} INFO - [2023-02-24 21:34:10,512] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:30:00+00:00, run_after=2023-02-24T21:35:00+00:00
[2023-02-24 21:34:10,533] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.604 seconds
[2023-02-24 21:34:41,016] {processor.py:153} INFO - Started process (PID=2887) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:34:41,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:34:41,051] {logging_mixin.py:115} INFO - [2023-02-24 21:34:41,051] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:34:44,491] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:34:44,531] {logging_mixin.py:115} INFO - [2023-02-24 21:34:44,531] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:34:44,575] {logging_mixin.py:115} INFO - [2023-02-24 21:34:44,575] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:30:00+00:00, run_after=2023-02-24T21:35:00+00:00
[2023-02-24 21:34:44,589] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.589 seconds
[2023-02-24 21:35:15,396] {processor.py:153} INFO - Started process (PID=2954) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:35:15,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:35:15,400] {logging_mixin.py:115} INFO - [2023-02-24 21:35:15,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:35:21,523] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:35:21,633] {logging_mixin.py:115} INFO - [2023-02-24 21:35:21,630] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:35:21,721] {logging_mixin.py:115} INFO - [2023-02-24 21:35:21,721] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:35:00+00:00, run_after=2023-02-24T21:40:00+00:00
[2023-02-24 21:35:21,748] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.357 seconds
[2023-02-24 21:35:52,884] {processor.py:153} INFO - Started process (PID=3020) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:35:52,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:35:52,889] {logging_mixin.py:115} INFO - [2023-02-24 21:35:52,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:35:56,724] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:35:56,827] {logging_mixin.py:115} INFO - [2023-02-24 21:35:56,827] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 21:35:56,877] {logging_mixin.py:115} INFO - [2023-02-24 21:35:56,877] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T21:35:00+00:00, run_after=2023-02-24T21:40:00+00:00
[2023-02-24 21:35:56,895] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.035 seconds
[2023-02-24 21:36:27,899] {processor.py:153} INFO - Started process (PID=3087) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:36:27,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:36:27,905] {logging_mixin.py:115} INFO - [2023-02-24 21:36:27,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:36:31,431] {logging_mixin.py:115} INFO - [2023-02-24 21:36:31,419] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 236, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:36:31,433] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:36:31,490] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.603 seconds
[2023-02-24 21:37:02,221] {processor.py:153} INFO - Started process (PID=3154) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:37:02,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:37:02,225] {logging_mixin.py:115} INFO - [2023-02-24 21:37:02,225] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:37:05,339] {logging_mixin.py:115} INFO - [2023-02-24 21:37:05,331] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 236, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:37:05,340] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:37:05,375] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.164 seconds
[2023-02-24 21:37:35,560] {processor.py:153} INFO - Started process (PID=3220) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:37:35,562] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:37:35,564] {logging_mixin.py:115} INFO - [2023-02-24 21:37:35,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:37:38,723] {logging_mixin.py:115} INFO - [2023-02-24 21:37:38,719] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 236, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:37:38,724] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:37:38,776] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.224 seconds
[2023-02-24 21:38:08,967] {processor.py:153} INFO - Started process (PID=3288) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:38:08,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:38:08,973] {logging_mixin.py:115} INFO - [2023-02-24 21:38:08,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:38:12,537] {logging_mixin.py:115} INFO - [2023-02-24 21:38:12,528] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 236, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:38:12,539] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:38:12,601] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.645 seconds
[2023-02-24 21:38:43,504] {processor.py:153} INFO - Started process (PID=3346) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:38:43,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:38:43,542] {logging_mixin.py:115} INFO - [2023-02-24 21:38:43,541] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:38:51,912] {logging_mixin.py:115} INFO - [2023-02-24 21:38:51,846] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 236, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:38:51,918] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:38:52,362] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 8.885 seconds
[2023-02-24 21:39:24,149] {processor.py:153} INFO - Started process (PID=3413) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:39:24,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:39:24,156] {logging_mixin.py:115} INFO - [2023-02-24 21:39:24,156] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:39:27,451] {logging_mixin.py:115} INFO - [2023-02-24 21:39:27,426] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 236, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:39:27,456] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:39:27,504] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.365 seconds
[2023-02-24 21:39:58,338] {processor.py:153} INFO - Started process (PID=3479) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:39:58,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:39:58,343] {logging_mixin.py:115} INFO - [2023-02-24 21:39:58,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:40:01,563] {logging_mixin.py:115} INFO - [2023-02-24 21:40:01,548] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 236, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:40:01,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:40:01,607] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.280 seconds
[2023-02-24 21:40:31,925] {processor.py:153} INFO - Started process (PID=3545) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:40:31,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:40:31,932] {logging_mixin.py:115} INFO - [2023-02-24 21:40:31,932] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:40:35,455] {logging_mixin.py:115} INFO - [2023-02-24 21:40:35,408] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 236, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:40:35,465] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:40:35,583] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.678 seconds
[2023-02-24 21:41:06,265] {processor.py:153} INFO - Started process (PID=3611) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:41:06,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:41:06,271] {logging_mixin.py:115} INFO - [2023-02-24 21:41:06,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:41:09,576] {logging_mixin.py:115} INFO - [2023-02-24 21:41:09,571] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 236, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:41:09,579] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:41:09,607] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.375 seconds
[2023-02-24 21:41:40,022] {processor.py:153} INFO - Started process (PID=3677) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:41:40,024] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:41:40,025] {logging_mixin.py:115} INFO - [2023-02-24 21:41:40,025] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:41:43,297] {logging_mixin.py:115} INFO - [2023-02-24 21:41:43,289] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 237, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:41:43,299] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:41:43,369] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.356 seconds
[2023-02-24 21:42:13,776] {processor.py:153} INFO - Started process (PID=3746) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:42:13,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:42:13,780] {logging_mixin.py:115} INFO - [2023-02-24 21:42:13,780] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:42:17,116] {logging_mixin.py:115} INFO - [2023-02-24 21:42:17,108] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 237, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:42:17,117] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:42:17,152] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.384 seconds
[2023-02-24 21:42:48,062] {processor.py:153} INFO - Started process (PID=3813) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:42:48,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:42:48,066] {logging_mixin.py:115} INFO - [2023-02-24 21:42:48,066] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:42:51,137] {logging_mixin.py:115} INFO - [2023-02-24 21:42:51,130] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 237, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:42:51,139] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:42:51,181] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.126 seconds
[2023-02-24 21:43:21,567] {processor.py:153} INFO - Started process (PID=3879) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:43:21,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:43:21,571] {logging_mixin.py:115} INFO - [2023-02-24 21:43:21,570] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:43:24,695] {logging_mixin.py:115} INFO - [2023-02-24 21:43:24,688] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 237, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:43:24,697] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:43:24,733] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.173 seconds
[2023-02-24 21:43:55,358] {processor.py:153} INFO - Started process (PID=3936) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:43:55,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:43:55,362] {logging_mixin.py:115} INFO - [2023-02-24 21:43:55,362] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:43:58,876] {logging_mixin.py:115} INFO - [2023-02-24 21:43:58,867] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 239, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:43:58,878] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:43:58,939] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.592 seconds
[2023-02-24 21:44:29,587] {processor.py:153} INFO - Started process (PID=4002) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:44:29,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:44:29,590] {logging_mixin.py:115} INFO - [2023-02-24 21:44:29,590] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:44:32,999] {logging_mixin.py:115} INFO - [2023-02-24 21:44:32,990] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 239, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:44:33,001] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:44:33,046] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.467 seconds
[2023-02-24 21:45:04,114] {processor.py:153} INFO - Started process (PID=4068) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:45:04,124] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:45:04,129] {logging_mixin.py:115} INFO - [2023-02-24 21:45:04,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:45:09,644] {logging_mixin.py:115} INFO - [2023-02-24 21:45:09,636] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 239, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:45:09,646] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:45:09,684] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.589 seconds
[2023-02-24 21:45:40,553] {processor.py:153} INFO - Started process (PID=4133) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:45:40,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:45:40,559] {logging_mixin.py:115} INFO - [2023-02-24 21:45:40,559] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:45:45,932] {logging_mixin.py:115} INFO - [2023-02-24 21:45:45,900] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 239, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:45:45,937] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:45:46,101] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.568 seconds
[2023-02-24 21:46:16,975] {processor.py:153} INFO - Started process (PID=4201) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:46:16,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:46:16,979] {logging_mixin.py:115} INFO - [2023-02-24 21:46:16,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:46:20,848] {logging_mixin.py:115} INFO - [2023-02-24 21:46:20,843] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 239, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:46:20,849] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:46:20,875] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.907 seconds
[2023-02-24 21:46:51,426] {processor.py:153} INFO - Started process (PID=4269) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:46:51,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:46:51,451] {logging_mixin.py:115} INFO - [2023-02-24 21:46:51,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:46:55,590] {logging_mixin.py:115} INFO - [2023-02-24 21:46:55,587] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 239, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:46:55,592] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:46:55,613] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.336 seconds
[2023-02-24 21:47:25,854] {processor.py:153} INFO - Started process (PID=4336) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:47:25,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:47:25,857] {logging_mixin.py:115} INFO - [2023-02-24 21:47:25,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:47:28,963] {logging_mixin.py:115} INFO - [2023-02-24 21:47:28,951] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 239, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:47:28,965] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:47:28,999] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.150 seconds
[2023-02-24 21:47:59,769] {processor.py:153} INFO - Started process (PID=4401) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:47:59,778] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:47:59,781] {logging_mixin.py:115} INFO - [2023-02-24 21:47:59,781] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:48:03,153] {logging_mixin.py:115} INFO - [2023-02-24 21:48:03,139] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:48:03,157] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:48:03,207] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.476 seconds
[2023-02-24 21:48:33,394] {processor.py:153} INFO - Started process (PID=4457) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:48:33,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:48:33,398] {logging_mixin.py:115} INFO - [2023-02-24 21:48:33,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:48:36,786] {logging_mixin.py:115} INFO - [2023-02-24 21:48:36,774] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:48:36,792] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:48:36,847] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.460 seconds
[2023-02-24 21:49:07,030] {processor.py:153} INFO - Started process (PID=4521) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:49:07,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:49:07,034] {logging_mixin.py:115} INFO - [2023-02-24 21:49:07,034] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:49:10,320] {logging_mixin.py:115} INFO - [2023-02-24 21:49:10,315] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:49:10,323] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:49:10,407] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.386 seconds
[2023-02-24 21:49:40,912] {processor.py:153} INFO - Started process (PID=4587) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:49:40,914] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:49:40,915] {logging_mixin.py:115} INFO - [2023-02-24 21:49:40,915] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:49:44,043] {logging_mixin.py:115} INFO - [2023-02-24 21:49:44,039] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:49:44,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:49:44,110] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.204 seconds
[2023-02-24 21:50:14,783] {processor.py:153} INFO - Started process (PID=4652) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:50:14,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:50:14,793] {logging_mixin.py:115} INFO - [2023-02-24 21:50:14,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:50:17,884] {logging_mixin.py:115} INFO - [2023-02-24 21:50:17,880] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:50:17,885] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:50:17,912] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.143 seconds
[2023-02-24 21:50:48,785] {processor.py:153} INFO - Started process (PID=4718) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:50:48,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:50:48,789] {logging_mixin.py:115} INFO - [2023-02-24 21:50:48,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:50:51,801] {logging_mixin.py:115} INFO - [2023-02-24 21:50:51,796] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:50:51,802] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:50:51,833] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.058 seconds
[2023-02-24 21:51:22,182] {processor.py:153} INFO - Started process (PID=4784) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:51:22,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:51:22,186] {logging_mixin.py:115} INFO - [2023-02-24 21:51:22,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:51:25,193] {logging_mixin.py:115} INFO - [2023-02-24 21:51:25,187] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:51:25,195] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:51:25,242] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.067 seconds
[2023-02-24 21:51:55,571] {processor.py:153} INFO - Started process (PID=4849) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:51:55,575] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:51:55,581] {logging_mixin.py:115} INFO - [2023-02-24 21:51:55,581] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:52:01,421] {logging_mixin.py:115} INFO - [2023-02-24 21:52:01,385] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:52:01,435] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:52:01,556] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.001 seconds
[2023-02-24 21:52:32,655] {processor.py:153} INFO - Started process (PID=4916) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:52:32,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:52:32,661] {logging_mixin.py:115} INFO - [2023-02-24 21:52:32,660] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:52:36,239] {logging_mixin.py:115} INFO - [2023-02-24 21:52:36,231] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:52:36,242] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:52:36,296] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.650 seconds
[2023-02-24 21:53:06,840] {processor.py:153} INFO - Started process (PID=4973) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:53:06,844] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:53:06,846] {logging_mixin.py:115} INFO - [2023-02-24 21:53:06,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:53:10,864] {logging_mixin.py:115} INFO - [2023-02-24 21:53:10,853] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:53:10,867] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:53:10,939] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.108 seconds
[2023-02-24 21:53:41,308] {processor.py:153} INFO - Started process (PID=5039) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:53:41,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:53:41,311] {logging_mixin.py:115} INFO - [2023-02-24 21:53:41,311] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:53:44,709] {logging_mixin.py:115} INFO - [2023-02-24 21:53:44,699] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:53:44,711] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:53:44,803] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.502 seconds
[2023-02-24 21:54:15,214] {processor.py:153} INFO - Started process (PID=5105) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:54:15,221] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:54:15,227] {logging_mixin.py:115} INFO - [2023-02-24 21:54:15,227] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:54:18,973] {logging_mixin.py:115} INFO - [2023-02-24 21:54:18,964] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:54:18,976] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:54:19,007] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.808 seconds
[2023-02-24 21:54:50,080] {processor.py:153} INFO - Started process (PID=5171) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:54:50,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:54:50,096] {logging_mixin.py:115} INFO - [2023-02-24 21:54:50,095] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:54:54,038] {logging_mixin.py:115} INFO - [2023-02-24 21:54:53,941] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:54:54,050] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:54:54,287] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.226 seconds
[2023-02-24 21:55:25,287] {processor.py:153} INFO - Started process (PID=5234) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:55:25,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:55:25,293] {logging_mixin.py:115} INFO - [2023-02-24 21:55:25,293] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:55:30,592] {logging_mixin.py:115} INFO - [2023-02-24 21:55:30,569] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:55:30,597] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:55:30,751] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.476 seconds
[2023-02-24 21:56:02,059] {processor.py:153} INFO - Started process (PID=5293) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:56:02,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:56:02,063] {logging_mixin.py:115} INFO - [2023-02-24 21:56:02,063] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:56:06,042] {logging_mixin.py:115} INFO - [2023-02-24 21:56:06,031] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:56:06,048] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:56:06,141] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.091 seconds
[2023-02-24 21:56:36,765] {processor.py:153} INFO - Started process (PID=5359) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:56:36,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:56:36,771] {logging_mixin.py:115} INFO - [2023-02-24 21:56:36,770] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:56:40,163] {logging_mixin.py:115} INFO - [2023-02-24 21:56:40,156] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:56:40,165] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:56:40,221] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.468 seconds
[2023-02-24 21:57:10,535] {processor.py:153} INFO - Started process (PID=5425) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:57:10,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:57:10,539] {logging_mixin.py:115} INFO - [2023-02-24 21:57:10,539] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:57:14,251] {logging_mixin.py:115} INFO - [2023-02-24 21:57:14,237] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:57:14,269] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:57:14,333] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.805 seconds
[2023-02-24 21:57:44,943] {processor.py:153} INFO - Started process (PID=5489) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:57:44,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:57:44,947] {logging_mixin.py:115} INFO - [2023-02-24 21:57:44,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:57:49,475] {logging_mixin.py:115} INFO - [2023-02-24 21:57:49,462] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:57:49,478] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:57:49,525] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.592 seconds
[2023-02-24 21:58:19,889] {processor.py:153} INFO - Started process (PID=5555) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:58:19,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:58:19,894] {logging_mixin.py:115} INFO - [2023-02-24 21:58:19,893] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:58:23,162] {logging_mixin.py:115} INFO - [2023-02-24 21:58:23,155] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:58:23,163] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:58:23,196] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.314 seconds
[2023-02-24 21:58:53,855] {processor.py:153} INFO - Started process (PID=5621) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:58:53,857] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:58:53,859] {logging_mixin.py:115} INFO - [2023-02-24 21:58:53,859] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:58:57,710] {logging_mixin.py:115} INFO - [2023-02-24 21:58:57,700] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:58:57,711] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:58:57,744] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.898 seconds
[2023-02-24 21:59:27,927] {processor.py:153} INFO - Started process (PID=5678) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 21:59:27,930] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 21:59:27,932] {logging_mixin.py:115} INFO - [2023-02-24 21:59:27,932] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:59:32,045] {logging_mixin.py:115} INFO - [2023-02-24 21:59:32,025] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 21:59:32,047] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 21:59:32,163] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.250 seconds
[2023-02-24 22:00:03,199] {processor.py:153} INFO - Started process (PID=5744) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:00:03,202] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:00:03,204] {logging_mixin.py:115} INFO - [2023-02-24 22:00:03,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:00:06,846] {logging_mixin.py:115} INFO - [2023-02-24 22:00:06,834] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:00:06,851] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:00:06,920] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.736 seconds
[2023-02-24 22:00:37,194] {processor.py:153} INFO - Started process (PID=5811) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:00:37,196] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:00:37,197] {logging_mixin.py:115} INFO - [2023-02-24 22:00:37,197] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:00:40,208] {logging_mixin.py:115} INFO - [2023-02-24 22:00:40,202] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:00:40,209] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:00:40,241] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.053 seconds
[2023-02-24 22:01:11,199] {processor.py:153} INFO - Started process (PID=5877) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:01:11,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:01:11,204] {logging_mixin.py:115} INFO - [2023-02-24 22:01:11,203] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:01:17,178] {logging_mixin.py:115} INFO - [2023-02-24 22:01:17,160] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:01:17,181] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:01:17,367] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.176 seconds
[2023-02-24 22:01:48,152] {processor.py:153} INFO - Started process (PID=5944) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:01:48,154] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:01:48,156] {logging_mixin.py:115} INFO - [2023-02-24 22:01:48,156] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:01:51,668] {logging_mixin.py:115} INFO - [2023-02-24 22:01:51,664] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:01:51,672] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:01:51,727] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.585 seconds
[2023-02-24 22:02:22,457] {processor.py:153} INFO - Started process (PID=6010) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:02:22,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:02:22,461] {logging_mixin.py:115} INFO - [2023-02-24 22:02:22,461] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:02:26,530] {logging_mixin.py:115} INFO - [2023-02-24 22:02:26,502] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:02:26,534] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:02:26,624] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.176 seconds
[2023-02-24 22:02:57,283] {processor.py:153} INFO - Started process (PID=6075) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:02:57,285] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:02:57,287] {logging_mixin.py:115} INFO - [2023-02-24 22:02:57,287] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:03:00,469] {logging_mixin.py:115} INFO - [2023-02-24 22:03:00,463] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:03:00,471] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:03:00,509] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.235 seconds
[2023-02-24 22:03:30,854] {processor.py:153} INFO - Started process (PID=6140) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:03:30,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:03:30,861] {logging_mixin.py:115} INFO - [2023-02-24 22:03:30,861] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:03:36,180] {logging_mixin.py:115} INFO - [2023-02-24 22:03:36,174] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:03:36,181] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:03:36,220] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.382 seconds
[2023-02-24 22:05:07,126] {processor.py:153} INFO - Started process (PID=6188) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:05:07,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:05:07,130] {logging_mixin.py:115} INFO - [2023-02-24 22:05:07,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:05:08,053] {logging_mixin.py:115} INFO - [2023-02-24 22:05:08,048] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:05:08,055] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:05:08,087] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.970 seconds
[2023-02-24 22:06:44,637] {processor.py:153} INFO - Started process (PID=6244) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:06:44,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:06:44,644] {logging_mixin.py:115} INFO - [2023-02-24 22:06:44,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:06:46,084] {logging_mixin.py:115} INFO - [2023-02-24 22:06:46,054] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:06:46,091] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:06:46,248] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.617 seconds
[2023-02-24 22:07:47,741] {processor.py:153} INFO - Started process (PID=6310) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:07:47,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:07:47,745] {logging_mixin.py:115} INFO - [2023-02-24 22:07:47,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:07:48,880] {logging_mixin.py:115} INFO - [2023-02-24 22:07:48,872] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:07:48,882] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:07:48,921] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.187 seconds
[2023-02-24 22:09:15,541] {processor.py:153} INFO - Started process (PID=6369) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:09:15,545] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:09:15,548] {logging_mixin.py:115} INFO - [2023-02-24 22:09:15,548] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:09:20,372] {logging_mixin.py:115} INFO - [2023-02-24 22:09:20,349] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:09:20,380] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:09:20,620] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.104 seconds
[2023-02-24 22:09:51,812] {processor.py:153} INFO - Started process (PID=6436) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:09:51,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:09:51,817] {logging_mixin.py:115} INFO - [2023-02-24 22:09:51,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:10:00,454] {logging_mixin.py:115} INFO - [2023-02-24 22:10:00,429] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:10:00,460] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:10:00,565] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 8.764 seconds
[2023-02-24 22:10:31,034] {processor.py:153} INFO - Started process (PID=6501) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:10:31,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:10:31,043] {logging_mixin.py:115} INFO - [2023-02-24 22:10:31,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:10:35,209] {logging_mixin.py:115} INFO - [2023-02-24 22:10:35,195] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:10:35,213] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:10:35,300] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.287 seconds
[2023-02-24 22:11:06,221] {processor.py:153} INFO - Started process (PID=6568) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:11:06,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:11:06,238] {logging_mixin.py:115} INFO - [2023-02-24 22:11:06,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:11:10,768] {logging_mixin.py:115} INFO - [2023-02-24 22:11:10,736] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:11:10,773] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:11:10,829] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.634 seconds
[2023-02-24 22:11:41,156] {processor.py:153} INFO - Started process (PID=6624) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:11:41,158] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:11:41,160] {logging_mixin.py:115} INFO - [2023-02-24 22:11:41,160] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:11:44,482] {logging_mixin.py:115} INFO - [2023-02-24 22:11:44,471] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:11:44,485] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:11:44,523] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.378 seconds
[2023-02-24 22:12:15,128] {processor.py:153} INFO - Started process (PID=6690) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:12:15,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:12:15,137] {logging_mixin.py:115} INFO - [2023-02-24 22:12:15,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:12:19,647] {logging_mixin.py:115} INFO - [2023-02-24 22:12:19,634] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:12:19,650] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:12:19,697] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.626 seconds
[2023-02-24 22:12:49,933] {processor.py:153} INFO - Started process (PID=6763) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:12:49,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:12:49,938] {logging_mixin.py:115} INFO - [2023-02-24 22:12:49,938] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:12:53,117] {logging_mixin.py:115} INFO - [2023-02-24 22:12:53,106] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:12:53,120] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:12:53,178] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.250 seconds
[2023-02-24 22:13:23,335] {processor.py:153} INFO - Started process (PID=6830) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:13:23,338] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:13:23,340] {logging_mixin.py:115} INFO - [2023-02-24 22:13:23,340] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:13:26,392] {logging_mixin.py:115} INFO - [2023-02-24 22:13:26,388] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:13:26,394] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:13:26,426] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.097 seconds
[2023-02-24 22:14:01,082] {processor.py:153} INFO - Started process (PID=6895) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:14:01,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:14:01,131] {logging_mixin.py:115} INFO - [2023-02-24 22:14:01,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:14:11,612] {logging_mixin.py:115} INFO - [2023-02-24 22:14:11,602] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:14:11,614] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:14:11,668] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 10.717 seconds
[2023-02-24 22:14:42,498] {processor.py:153} INFO - Started process (PID=6964) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:14:42,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:14:42,502] {logging_mixin.py:115} INFO - [2023-02-24 22:14:42,502] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:14:46,600] {logging_mixin.py:115} INFO - [2023-02-24 22:14:46,587] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:14:46,602] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:14:46,739] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.249 seconds
[2023-02-24 22:15:16,898] {processor.py:153} INFO - Started process (PID=7030) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:15:16,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:15:16,902] {logging_mixin.py:115} INFO - [2023-02-24 22:15:16,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:15:19,785] {logging_mixin.py:115} INFO - [2023-02-24 22:15:19,782] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:15:19,787] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:15:19,812] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.921 seconds
[2023-02-24 22:15:50,624] {processor.py:153} INFO - Started process (PID=7087) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:15:50,627] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:15:50,631] {logging_mixin.py:115} INFO - [2023-02-24 22:15:50,631] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:15:54,692] {logging_mixin.py:115} INFO - [2023-02-24 22:15:54,680] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:15:54,694] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:15:54,748] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.138 seconds
[2023-02-24 22:16:25,233] {processor.py:153} INFO - Started process (PID=7157) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:16:25,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:16:25,237] {logging_mixin.py:115} INFO - [2023-02-24 22:16:25,237] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:16:28,096] {logging_mixin.py:115} INFO - [2023-02-24 22:16:28,093] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:16:28,097] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:16:28,121] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.897 seconds
[2023-02-24 22:16:58,922] {processor.py:153} INFO - Started process (PID=7227) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:16:58,924] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:16:58,926] {logging_mixin.py:115} INFO - [2023-02-24 22:16:58,926] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:17:01,827] {logging_mixin.py:115} INFO - [2023-02-24 22:17:01,824] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:17:01,828] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:17:01,855] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.941 seconds
[2023-02-24 22:17:32,702] {processor.py:153} INFO - Started process (PID=7301) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:17:32,705] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:17:32,707] {logging_mixin.py:115} INFO - [2023-02-24 22:17:32,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:17:35,931] {logging_mixin.py:115} INFO - [2023-02-24 22:17:35,926] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:17:35,933] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:17:35,985] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.303 seconds
[2023-02-24 22:18:06,305] {processor.py:153} INFO - Started process (PID=7367) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:18:06,308] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:18:06,309] {logging_mixin.py:115} INFO - [2023-02-24 22:18:06,309] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:18:09,351] {logging_mixin.py:115} INFO - [2023-02-24 22:18:09,344] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:18:09,352] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:18:09,386] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.088 seconds
[2023-02-24 22:18:39,674] {processor.py:153} INFO - Started process (PID=7439) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:18:39,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:18:39,680] {logging_mixin.py:115} INFO - [2023-02-24 22:18:39,680] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:18:42,630] {logging_mixin.py:115} INFO - [2023-02-24 22:18:42,624] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:18:42,631] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:18:42,666] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.999 seconds
[2023-02-24 22:19:13,568] {processor.py:153} INFO - Started process (PID=7505) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:19:13,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:19:13,572] {logging_mixin.py:115} INFO - [2023-02-24 22:19:13,572] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:19:16,721] {logging_mixin.py:115} INFO - [2023-02-24 22:19:16,708] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:19:16,723] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:19:16,763] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.204 seconds
[2023-02-24 22:19:47,298] {processor.py:153} INFO - Started process (PID=7565) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:19:47,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:19:47,301] {logging_mixin.py:115} INFO - [2023-02-24 22:19:47,301] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:19:50,276] {logging_mixin.py:115} INFO - [2023-02-24 22:19:50,272] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:19:50,277] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:19:50,306] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.015 seconds
[2023-02-24 22:20:21,015] {processor.py:153} INFO - Started process (PID=7632) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:20:21,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:20:21,017] {logging_mixin.py:115} INFO - [2023-02-24 22:20:21,017] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:20:23,985] {logging_mixin.py:115} INFO - [2023-02-24 22:20:23,981] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:20:23,987] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:20:24,011] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.999 seconds
[2023-02-24 22:20:54,229] {processor.py:153} INFO - Started process (PID=7700) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:20:54,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:20:54,241] {logging_mixin.py:115} INFO - [2023-02-24 22:20:54,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:20:57,310] {logging_mixin.py:115} INFO - [2023-02-24 22:20:57,304] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:20:57,311] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:20:57,349] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.133 seconds
[2023-02-24 22:21:28,003] {processor.py:153} INFO - Started process (PID=7766) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:21:28,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:21:28,006] {logging_mixin.py:115} INFO - [2023-02-24 22:21:28,006] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:21:30,856] {logging_mixin.py:115} INFO - [2023-02-24 22:21:30,853] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:21:30,857] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:21:30,886] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.891 seconds
[2023-02-24 22:22:01,083] {processor.py:153} INFO - Started process (PID=7832) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:22:01,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:22:01,087] {logging_mixin.py:115} INFO - [2023-02-24 22:22:01,087] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:22:04,366] {logging_mixin.py:115} INFO - [2023-02-24 22:22:04,359] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:22:04,367] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:22:04,392] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.318 seconds
[2023-02-24 22:22:35,122] {processor.py:153} INFO - Started process (PID=7896) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:22:35,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:22:35,128] {logging_mixin.py:115} INFO - [2023-02-24 22:22:35,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:22:41,012] {logging_mixin.py:115} INFO - [2023-02-24 22:22:40,991] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:22:41,037] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:22:41,144] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.033 seconds
[2023-02-24 22:23:12,005] {processor.py:153} INFO - Started process (PID=7957) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:23:12,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:23:12,008] {logging_mixin.py:115} INFO - [2023-02-24 22:23:12,008] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:23:14,917] {logging_mixin.py:115} INFO - [2023-02-24 22:23:14,914] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:23:14,918] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:23:14,951] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.955 seconds
[2023-02-24 22:23:45,658] {processor.py:153} INFO - Started process (PID=8023) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:23:45,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:23:45,662] {logging_mixin.py:115} INFO - [2023-02-24 22:23:45,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:23:48,423] {logging_mixin.py:115} INFO - [2023-02-24 22:23:48,419] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:23:48,424] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:23:48,448] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.795 seconds
[2023-02-24 22:24:19,109] {processor.py:153} INFO - Started process (PID=8090) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:24:19,112] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:24:19,114] {logging_mixin.py:115} INFO - [2023-02-24 22:24:19,113] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:24:22,139] {logging_mixin.py:115} INFO - [2023-02-24 22:24:22,134] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:24:22,140] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:24:22,172] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.075 seconds
[2023-02-24 22:24:52,856] {processor.py:153} INFO - Started process (PID=8156) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:24:52,861] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:24:52,868] {logging_mixin.py:115} INFO - [2023-02-24 22:24:52,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:24:56,726] {logging_mixin.py:115} INFO - [2023-02-24 22:24:56,722] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:24:56,727] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:24:56,779] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.955 seconds
[2023-02-24 22:25:27,379] {processor.py:153} INFO - Started process (PID=8222) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:25:27,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:25:27,384] {logging_mixin.py:115} INFO - [2023-02-24 22:25:27,383] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:25:30,542] {logging_mixin.py:115} INFO - [2023-02-24 22:25:30,530] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:25:30,546] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:25:30,591] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.223 seconds
[2023-02-24 22:26:00,941] {processor.py:153} INFO - Started process (PID=8290) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:26:00,944] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:26:00,947] {logging_mixin.py:115} INFO - [2023-02-24 22:26:00,946] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:26:05,072] {logging_mixin.py:115} INFO - [2023-02-24 22:26:05,065] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:26:05,073] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:26:05,114] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.183 seconds
[2023-02-24 22:26:35,256] {processor.py:153} INFO - Started process (PID=8361) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:26:35,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:26:35,261] {logging_mixin.py:115} INFO - [2023-02-24 22:26:35,261] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:26:39,461] {logging_mixin.py:115} INFO - [2023-02-24 22:26:39,457] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:26:39,462] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:26:39,496] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.250 seconds
[2023-02-24 22:27:10,403] {processor.py:153} INFO - Started process (PID=8424) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:27:10,405] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:27:10,406] {logging_mixin.py:115} INFO - [2023-02-24 22:27:10,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:27:13,806] {logging_mixin.py:115} INFO - [2023-02-24 22:27:13,800] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:27:13,808] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:27:13,846] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.450 seconds
[2023-02-24 22:27:44,327] {processor.py:153} INFO - Started process (PID=8494) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:27:44,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:27:44,330] {logging_mixin.py:115} INFO - [2023-02-24 22:27:44,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:27:47,366] {logging_mixin.py:115} INFO - [2023-02-24 22:27:47,356] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:27:47,368] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:27:47,411] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.094 seconds
[2023-02-24 22:28:17,996] {processor.py:153} INFO - Started process (PID=8563) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:28:17,999] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:28:18,002] {logging_mixin.py:115} INFO - [2023-02-24 22:28:18,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:28:22,372] {logging_mixin.py:115} INFO - [2023-02-24 22:28:22,303] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:28:22,381] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:28:22,862] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.871 seconds
[2023-02-24 22:28:55,450] {processor.py:153} INFO - Started process (PID=8620) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:28:55,452] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:28:55,453] {logging_mixin.py:115} INFO - [2023-02-24 22:28:55,453] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:28:58,726] {logging_mixin.py:115} INFO - [2023-02-24 22:28:58,720] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:28:58,728] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:28:58,755] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.312 seconds
[2023-02-24 22:29:28,988] {processor.py:153} INFO - Started process (PID=8686) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:29:28,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:29:28,994] {logging_mixin.py:115} INFO - [2023-02-24 22:29:28,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:29:32,355] {logging_mixin.py:115} INFO - [2023-02-24 22:29:32,351] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:29:32,357] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:29:32,385] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.406 seconds
[2023-02-24 22:30:03,274] {processor.py:153} INFO - Started process (PID=8752) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:30:03,277] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:30:03,284] {logging_mixin.py:115} INFO - [2023-02-24 22:30:03,284] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:30:08,366] {logging_mixin.py:115} INFO - [2023-02-24 22:30:08,323] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:30:08,371] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:30:08,581] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.315 seconds
[2023-02-24 22:30:39,737] {processor.py:153} INFO - Started process (PID=8820) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:30:39,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:30:39,742] {logging_mixin.py:115} INFO - [2023-02-24 22:30:39,742] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:30:42,879] {logging_mixin.py:115} INFO - [2023-02-24 22:30:42,875] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:30:42,881] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:30:42,913] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.190 seconds
[2023-02-24 22:31:13,692] {processor.py:153} INFO - Started process (PID=8887) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:31:13,695] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:31:13,696] {logging_mixin.py:115} INFO - [2023-02-24 22:31:13,696] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:31:18,565] {logging_mixin.py:115} INFO - [2023-02-24 22:31:18,499] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:31:18,570] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:31:18,734] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.053 seconds
[2023-02-24 22:31:49,625] {processor.py:153} INFO - Started process (PID=8947) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:31:49,628] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:31:49,629] {logging_mixin.py:115} INFO - [2023-02-24 22:31:49,629] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:31:52,817] {logging_mixin.py:115} INFO - [2023-02-24 22:31:52,809] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:31:52,818] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:31:52,853] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.238 seconds
[2023-02-24 22:32:23,060] {processor.py:153} INFO - Started process (PID=9013) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:32:23,063] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:32:23,064] {logging_mixin.py:115} INFO - [2023-02-24 22:32:23,064] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:32:26,157] {logging_mixin.py:115} INFO - [2023-02-24 22:32:26,143] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:32:26,161] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:32:26,188] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.138 seconds
[2023-02-24 22:32:56,781] {processor.py:153} INFO - Started process (PID=9081) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:32:56,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:32:56,785] {logging_mixin.py:115} INFO - [2023-02-24 22:32:56,785] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:32:59,863] {logging_mixin.py:115} INFO - [2023-02-24 22:32:59,859] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:32:59,865] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:32:59,907] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.136 seconds
[2023-02-24 22:33:30,693] {processor.py:153} INFO - Started process (PID=9150) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:33:30,697] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:33:30,699] {logging_mixin.py:115} INFO - [2023-02-24 22:33:30,699] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:33:34,493] {logging_mixin.py:115} INFO - [2023-02-24 22:33:34,479] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    # %%
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 168, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 75, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:33:34,497] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:33:34,543] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.861 seconds
[2023-02-24 22:34:05,396] {processor.py:153} INFO - Started process (PID=9216) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:34:05,399] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:34:05,401] {logging_mixin.py:115} INFO - [2023-02-24 22:34:05,401] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:34:08,526] {logging_mixin.py:115} INFO - [2023-02-24 22:34:08,516] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 238, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 169, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 76, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:34:08,531] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:34:08,581] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.197 seconds
[2023-02-24 22:34:39,145] {processor.py:153} INFO - Started process (PID=9284) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:34:39,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:34:39,150] {logging_mixin.py:115} INFO - [2023-02-24 22:34:39,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:34:42,878] {logging_mixin.py:115} INFO - [2023-02-24 22:34:42,846] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 239, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 77, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:34:42,880] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:34:43,037] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.900 seconds
[2023-02-24 22:35:13,811] {processor.py:153} INFO - Started process (PID=9352) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:35:13,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:35:13,818] {logging_mixin.py:115} INFO - [2023-02-24 22:35:13,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:35:17,262] {logging_mixin.py:115} INFO - [2023-02-24 22:35:17,254] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:35:17,263] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:35:17,326] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.534 seconds
[2023-02-24 22:35:47,716] {processor.py:153} INFO - Started process (PID=9421) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:35:47,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:35:47,719] {logging_mixin.py:115} INFO - [2023-02-24 22:35:47,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:35:50,823] {logging_mixin.py:115} INFO - [2023-02-24 22:35:50,818] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:35:50,825] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:35:50,879] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.171 seconds
[2023-02-24 22:36:21,469] {processor.py:153} INFO - Started process (PID=9489) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:36:21,478] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:36:21,481] {logging_mixin.py:115} INFO - [2023-02-24 22:36:21,481] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:36:25,022] {logging_mixin.py:115} INFO - [2023-02-24 22:36:25,016] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:36:25,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:36:25,046] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.586 seconds
[2023-02-24 22:36:55,344] {processor.py:153} INFO - Started process (PID=9546) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:36:55,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:36:55,349] {logging_mixin.py:115} INFO - [2023-02-24 22:36:55,349] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:36:59,605] {logging_mixin.py:115} INFO - [2023-02-24 22:36:59,600] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:36:59,607] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:36:59,659] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.328 seconds
[2023-02-24 22:37:30,477] {processor.py:153} INFO - Started process (PID=9614) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:37:30,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:37:30,480] {logging_mixin.py:115} INFO - [2023-02-24 22:37:30,480] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:37:33,575] {logging_mixin.py:115} INFO - [2023-02-24 22:37:33,566] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:37:33,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:37:33,612] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.145 seconds
[2023-02-24 22:38:04,413] {processor.py:153} INFO - Started process (PID=9685) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:38:04,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:38:04,420] {logging_mixin.py:115} INFO - [2023-02-24 22:38:04,420] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:38:07,554] {logging_mixin.py:115} INFO - [2023-02-24 22:38:07,548] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:38:07,556] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:38:07,611] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.210 seconds
[2023-02-24 22:38:37,916] {processor.py:153} INFO - Started process (PID=9752) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:38:37,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:38:37,929] {logging_mixin.py:115} INFO - [2023-02-24 22:38:37,929] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:38:41,300] {logging_mixin.py:115} INFO - [2023-02-24 22:38:41,268] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:38:41,352] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:38:41,631] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.727 seconds
[2023-02-24 22:39:13,370] {processor.py:153} INFO - Started process (PID=9822) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:39:13,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:39:13,420] {logging_mixin.py:115} INFO - [2023-02-24 22:39:13,419] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:39:17,751] {logging_mixin.py:115} INFO - [2023-02-24 22:39:17,738] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:39:17,754] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:39:17,807] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.545 seconds
[2023-02-24 22:39:48,846] {processor.py:153} INFO - Started process (PID=9888) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:39:48,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:39:48,851] {logging_mixin.py:115} INFO - [2023-02-24 22:39:48,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:39:52,083] {logging_mixin.py:115} INFO - [2023-02-24 22:39:52,079] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:39:52,085] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:39:52,111] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.272 seconds
[2023-02-24 22:40:22,473] {processor.py:153} INFO - Started process (PID=9955) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:40:22,477] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:40:22,480] {logging_mixin.py:115} INFO - [2023-02-24 22:40:22,480] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:40:27,461] {logging_mixin.py:115} INFO - [2023-02-24 22:40:27,421] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:40:27,467] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:40:27,682] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.223 seconds
[2023-02-24 22:40:49,697] {processor.py:153} INFO - Started process (PID=10011) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:40:49,701] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:40:49,705] {logging_mixin.py:115} INFO - [2023-02-24 22:40:49,705] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:40:52,846] {logging_mixin.py:115} INFO - [2023-02-24 22:40:52,838] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:40:52,847] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:40:52,892] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.218 seconds
[2023-02-24 22:41:23,170] {processor.py:153} INFO - Started process (PID=10078) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:41:23,174] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:41:23,176] {logging_mixin.py:115} INFO - [2023-02-24 22:41:23,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:41:26,344] {logging_mixin.py:115} INFO - [2023-02-24 22:41:26,338] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:41:26,345] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:41:26,373] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.231 seconds
[2023-02-24 22:41:56,844] {processor.py:153} INFO - Started process (PID=10144) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:41:56,848] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:41:56,850] {logging_mixin.py:115} INFO - [2023-02-24 22:41:56,850] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:42:00,360] {logging_mixin.py:115} INFO - [2023-02-24 22:42:00,349] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 240, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:42:00,366] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:42:00,402] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.576 seconds
[2023-02-24 22:42:30,646] {processor.py:153} INFO - Started process (PID=10202) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:42:30,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:42:30,649] {logging_mixin.py:115} INFO - [2023-02-24 22:42:30,649] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:42:34,064] {logging_mixin.py:115} INFO - [2023-02-24 22:42:34,059] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 243, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 171, in aws_extract_data_to_sqlite
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:42:34,067] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:42:34,097] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.455 seconds
[2023-02-24 22:43:04,617] {processor.py:153} INFO - Started process (PID=10272) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:04,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:43:04,621] {logging_mixin.py:115} INFO - [2023-02-24 22:43:04,621] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:09,307] {logging_mixin.py:115} INFO - [2023-02-24 22:43:09,301] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:43:09,308] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:09,371] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.762 seconds
[2023-02-24 22:43:23,298] {processor.py:153} INFO - Started process (PID=10323) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:23,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:43:23,301] {logging_mixin.py:115} INFO - [2023-02-24 22:43:23,301] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:23,310] {logging_mixin.py:115} INFO - [2023-02-24 22:43:23,308] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 96
    sleep_process >> aws_to_sql_extraction_process >>
                                                    ^
SyntaxError: invalid syntax
[2023-02-24 22:43:23,311] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:23,362] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.071 seconds
[2023-02-24 22:43:26,384] {processor.py:153} INFO - Started process (PID=10324) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:26,385] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:43:26,387] {logging_mixin.py:115} INFO - [2023-02-24 22:43:26,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:27,542] {logging_mixin.py:115} INFO - [2023-02-24 22:43:27,534] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:43:27,544] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:27,593] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.217 seconds
[2023-02-24 22:43:35,359] {processor.py:153} INFO - Started process (PID=10341) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:35,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:43:35,378] {logging_mixin.py:115} INFO - [2023-02-24 22:43:35,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:38,885] {logging_mixin.py:115} INFO - [2023-02-24 22:43:38,877] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:43:38,887] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:43:38,946] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.599 seconds
[2023-02-24 22:44:09,231] {processor.py:153} INFO - Started process (PID=10413) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:44:09,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:44:09,240] {logging_mixin.py:115} INFO - [2023-02-24 22:44:09,240] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:44:15,330] {logging_mixin.py:115} INFO - [2023-02-24 22:44:15,318] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:44:15,336] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:44:15,374] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.174 seconds
[2023-02-24 22:44:45,633] {processor.py:153} INFO - Started process (PID=10484) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:44:45,635] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:44:45,636] {logging_mixin.py:115} INFO - [2023-02-24 22:44:45,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:44:49,501] {logging_mixin.py:115} INFO - [2023-02-24 22:44:49,497] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:44:49,503] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:44:49,555] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.926 seconds
[2023-02-24 22:45:20,380] {processor.py:153} INFO - Started process (PID=10551) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:45:20,385] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:45:20,406] {logging_mixin.py:115} INFO - [2023-02-24 22:45:20,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:45:25,726] {logging_mixin.py:115} INFO - [2023-02-24 22:45:25,719] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:45:25,728] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:45:25,754] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.447 seconds
[2023-02-24 22:45:56,505] {processor.py:153} INFO - Started process (PID=10611) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:45:56,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:45:56,508] {logging_mixin.py:115} INFO - [2023-02-24 22:45:56,508] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:45:59,634] {logging_mixin.py:115} INFO - [2023-02-24 22:45:59,630] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:45:59,636] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:45:59,684] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.186 seconds
[2023-02-24 22:46:30,167] {processor.py:153} INFO - Started process (PID=10677) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:46:30,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:46:30,171] {logging_mixin.py:115} INFO - [2023-02-24 22:46:30,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:46:33,324] {logging_mixin.py:115} INFO - [2023-02-24 22:46:33,316] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:46:33,326] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:46:33,421] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.273 seconds
[2023-02-24 22:47:04,013] {processor.py:153} INFO - Started process (PID=10750) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:47:04,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:47:04,019] {logging_mixin.py:115} INFO - [2023-02-24 22:47:04,019] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:47:07,538] {logging_mixin.py:115} INFO - [2023-02-24 22:47:07,531] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:47:07,540] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:47:07,584] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.582 seconds
[2023-02-24 22:47:38,293] {processor.py:153} INFO - Started process (PID=10818) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:47:38,297] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:47:38,303] {logging_mixin.py:115} INFO - [2023-02-24 22:47:38,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:47:41,421] {logging_mixin.py:115} INFO - [2023-02-24 22:47:41,416] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:47:41,423] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:47:41,450] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.169 seconds
[2023-02-24 22:48:11,939] {processor.py:153} INFO - Started process (PID=10885) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:48:11,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:48:11,944] {logging_mixin.py:115} INFO - [2023-02-24 22:48:11,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:48:15,449] {logging_mixin.py:115} INFO - [2023-02-24 22:48:15,432] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:48:15,450] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:48:15,481] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.553 seconds
[2023-02-24 22:48:45,711] {processor.py:153} INFO - Started process (PID=10943) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:48:45,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:48:45,717] {logging_mixin.py:115} INFO - [2023-02-24 22:48:45,717] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:48:49,322] {logging_mixin.py:115} INFO - [2023-02-24 22:48:49,250] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:48:49,329] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:48:49,416] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.722 seconds
[2023-02-24 22:49:20,122] {processor.py:153} INFO - Started process (PID=11012) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:49:20,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:49:20,126] {logging_mixin.py:115} INFO - [2023-02-24 22:49:20,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:49:26,099] {logging_mixin.py:115} INFO - [2023-02-24 22:49:26,055] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:49:26,127] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:49:26,299] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.185 seconds
[2023-02-24 22:49:57,781] {processor.py:153} INFO - Started process (PID=11080) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:49:57,785] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:49:57,786] {logging_mixin.py:115} INFO - [2023-02-24 22:49:57,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:50:00,903] {logging_mixin.py:115} INFO - [2023-02-24 22:50:00,897] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:50:00,904] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:50:00,946] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.175 seconds
[2023-02-24 22:50:31,946] {processor.py:153} INFO - Started process (PID=11146) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:50:31,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:50:31,954] {logging_mixin.py:115} INFO - [2023-02-24 22:50:31,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:50:36,558] {logging_mixin.py:115} INFO - [2023-02-24 22:50:36,547] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:50:36,564] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:50:36,739] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.810 seconds
[2023-02-24 22:51:07,959] {processor.py:153} INFO - Started process (PID=11212) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:51:07,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:51:07,964] {logging_mixin.py:115} INFO - [2023-02-24 22:51:07,963] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:51:14,015] {logging_mixin.py:115} INFO - [2023-02-24 22:51:13,968] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:51:14,018] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:51:14,165] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.227 seconds
[2023-02-24 22:51:45,493] {processor.py:153} INFO - Started process (PID=11269) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:51:45,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:51:45,498] {logging_mixin.py:115} INFO - [2023-02-24 22:51:45,498] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:51:51,756] {logging_mixin.py:115} INFO - [2023-02-24 22:51:51,732] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:51:51,759] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:51:51,835] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.355 seconds
[2023-02-24 22:52:22,362] {processor.py:153} INFO - Started process (PID=11335) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:52:22,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:52:22,366] {logging_mixin.py:115} INFO - [2023-02-24 22:52:22,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:52:25,976] {logging_mixin.py:115} INFO - [2023-02-24 22:52:25,964] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:52:25,979] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:52:26,059] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.706 seconds
[2023-02-24 22:52:56,414] {processor.py:153} INFO - Started process (PID=11401) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:52:56,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:52:56,421] {logging_mixin.py:115} INFO - [2023-02-24 22:52:56,421] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:53:02,020] {logging_mixin.py:115} INFO - [2023-02-24 22:53:02,010] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:53:02,022] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:53:02,070] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 5.682 seconds
[2023-02-24 22:53:32,778] {processor.py:153} INFO - Started process (PID=11467) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:53:32,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:53:32,783] {logging_mixin.py:115} INFO - [2023-02-24 22:53:32,783] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:53:36,024] {logging_mixin.py:115} INFO - [2023-02-24 22:53:36,016] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:53:36,025] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:53:36,085] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.320 seconds
[2023-02-24 22:54:06,836] {processor.py:153} INFO - Started process (PID=11533) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:54:06,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:54:06,842] {logging_mixin.py:115} INFO - [2023-02-24 22:54:06,842] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:54:10,199] {logging_mixin.py:115} INFO - [2023-02-24 22:54:10,193] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
    metadata_instance = Metadata()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
    self.conn = sql.connect(self.database_name)
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:54:10,201] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:54:10,283] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.464 seconds
[2023-02-24 22:54:41,081] {processor.py:153} INFO - Started process (PID=11601) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:54:41,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:54:41,089] {logging_mixin.py:115} INFO - [2023-02-24 22:54:41,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:54:44,723] {logging_mixin.py:115} INFO - [2023-02-24 22:54:44,709] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 170, in <module>
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 78, in __init__
sqlite3.OperationalError: unable to open database file
[2023-02-24 22:54:44,726] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:54:44,795] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.737 seconds
[2023-02-24 22:55:15,762] {processor.py:153} INFO - Started process (PID=11658) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:55:15,768] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:55:15,771] {logging_mixin.py:115} INFO - [2023-02-24 22:55:15,771] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:55:19,533] {logging_mixin.py:115} INFO - [2023-02-24 22:55:19,526] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 248, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 187, in aws_extract_data_to_sqlite
    metadata_instance.truncate_table_data()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 89, in truncate_table_data
    self.cursor.execute(str_table_1_drop)
sqlite3.OperationalError: no such table: goes_metadata
[2023-02-24 22:55:19,537] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:55:19,651] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.916 seconds
[2023-02-24 22:55:51,277] {processor.py:153} INFO - Started process (PID=11724) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:55:51,282] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:55:51,287] {logging_mixin.py:115} INFO - [2023-02-24 22:55:51,287] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:55:55,010] {logging_mixin.py:115} INFO - [2023-02-24 22:55:55,006] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 248, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 187, in aws_extract_data_to_sqlite
    metadata_instance.truncate_table_data()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 89, in truncate_table_data
    self.cursor.execute(str_table_1_drop)
sqlite3.OperationalError: no such table: goes_metadata
[2023-02-24 22:55:55,011] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:55:55,073] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.852 seconds
[2023-02-24 22:56:25,410] {processor.py:153} INFO - Started process (PID=11780) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:56:25,412] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:56:25,416] {logging_mixin.py:115} INFO - [2023-02-24 22:56:25,415] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:56:30,060] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 22:56:30,061] {logging_mixin.py:115} INFO - todays 24 02 2023 22 055
[2023-02-24 22:56:30,062] {logging_mixin.py:115} INFO - here
[2023-02-24 22:56:30,144] {logging_mixin.py:115} INFO - [2023-02-24 22:56:30,134] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 248, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 197, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 22:56:30,146] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:56:30,186] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.797 seconds
[2023-02-24 22:57:00,912] {processor.py:153} INFO - Started process (PID=11845) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:57:00,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:57:00,919] {logging_mixin.py:115} INFO - [2023-02-24 22:57:00,919] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:57:00,991] {logging_mixin.py:115} INFO - [2023-02-24 22:57:00,966] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 92
    expect:
         ^
SyntaxError: invalid syntax
[2023-02-24 22:57:01,002] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:57:01,084] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.202 seconds
[2023-02-24 22:57:32,172] {processor.py:153} INFO - Started process (PID=11908) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:57:32,179] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:57:32,182] {logging_mixin.py:115} INFO - [2023-02-24 22:57:32,182] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:57:36,858] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 22:57:36,859] {logging_mixin.py:115} INFO - todays 24 02 2023 22 055
[2023-02-24 22:57:36,860] {logging_mixin.py:115} INFO - here
[2023-02-24 22:57:36,953] {logging_mixin.py:115} INFO - [2023-02-24 22:57:36,943] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 22:57:36,954] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:57:37,048] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.914 seconds
[2023-02-24 22:58:07,337] {processor.py:153} INFO - Started process (PID=11965) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:58:07,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:58:07,342] {logging_mixin.py:115} INFO - [2023-02-24 22:58:07,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:58:11,252] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 22:58:11,253] {logging_mixin.py:115} INFO - todays 24 02 2023 22 055
[2023-02-24 22:58:11,254] {logging_mixin.py:115} INFO - here
[2023-02-24 22:58:11,297] {logging_mixin.py:115} INFO - [2023-02-24 22:58:11,291] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 22:58:11,299] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:58:11,379] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.059 seconds
[2023-02-24 22:58:42,111] {processor.py:153} INFO - Started process (PID=12031) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:58:42,121] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:58:42,132] {logging_mixin.py:115} INFO - [2023-02-24 22:58:42,132] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:58:46,412] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 22:58:46,414] {logging_mixin.py:115} INFO - todays 24 02 2023 22 055
[2023-02-24 22:58:46,416] {logging_mixin.py:115} INFO - here
[2023-02-24 22:58:46,510] {logging_mixin.py:115} INFO - [2023-02-24 22:58:46,499] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 22:58:46,512] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:58:46,588] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.530 seconds
[2023-02-24 22:59:17,228] {processor.py:153} INFO - Started process (PID=12097) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:59:17,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:59:17,233] {logging_mixin.py:115} INFO - [2023-02-24 22:59:17,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:59:20,777] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 22:59:20,778] {logging_mixin.py:115} INFO - todays 24 02 2023 22 055
[2023-02-24 22:59:20,779] {logging_mixin.py:115} INFO - here
[2023-02-24 22:59:20,818] {logging_mixin.py:115} INFO - [2023-02-24 22:59:20,812] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 22:59:20,821] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:59:20,867] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.649 seconds
[2023-02-24 22:59:51,298] {processor.py:153} INFO - Started process (PID=12163) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 22:59:51,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 22:59:51,303] {logging_mixin.py:115} INFO - [2023-02-24 22:59:51,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:59:55,383] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 22:59:55,384] {logging_mixin.py:115} INFO - todays 24 02 2023 22 055
[2023-02-24 22:59:55,385] {logging_mixin.py:115} INFO - here
[2023-02-24 22:59:55,454] {logging_mixin.py:115} INFO - [2023-02-24 22:59:55,447] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 22:59:55,457] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 22:59:55,537] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.250 seconds
[2023-02-24 23:00:26,271] {processor.py:153} INFO - Started process (PID=12226) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:00:26,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:00:26,299] {logging_mixin.py:115} INFO - [2023-02-24 23:00:26,299] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:00:32,135] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:00:32,138] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:00:32,140] {logging_mixin.py:115} INFO - here
[2023-02-24 23:00:32,282] {logging_mixin.py:115} INFO - [2023-02-24 23:00:32,270] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 23:00:32,290] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:00:32,456] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.214 seconds
[2023-02-24 23:01:03,716] {processor.py:153} INFO - Started process (PID=12285) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:01:03,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:01:03,721] {logging_mixin.py:115} INFO - [2023-02-24 23:01:03,721] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:01:07,031] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:01:07,038] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:01:07,040] {logging_mixin.py:115} INFO - here
[2023-02-24 23:01:07,094] {logging_mixin.py:115} INFO - [2023-02-24 23:01:07,083] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 23:01:07,098] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:01:07,182] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.474 seconds
[2023-02-24 23:01:37,641] {processor.py:153} INFO - Started process (PID=12351) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:01:37,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:01:37,649] {logging_mixin.py:115} INFO - [2023-02-24 23:01:37,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:01:41,166] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:01:41,168] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:01:41,168] {logging_mixin.py:115} INFO - here
[2023-02-24 23:01:41,213] {logging_mixin.py:115} INFO - [2023-02-24 23:01:41,206] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 23:01:41,215] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:01:41,255] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.649 seconds
[2023-02-24 23:02:11,621] {processor.py:153} INFO - Started process (PID=12416) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:02:11,623] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:02:11,625] {logging_mixin.py:115} INFO - [2023-02-24 23:02:11,625] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:02:15,087] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:02:15,088] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:02:15,089] {logging_mixin.py:115} INFO - here
[2023-02-24 23:02:15,145] {logging_mixin.py:115} INFO - [2023-02-24 23:02:15,138] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 23:02:15,148] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:02:15,197] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.584 seconds
[2023-02-24 23:02:45,798] {processor.py:153} INFO - Started process (PID=12482) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:02:45,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:02:45,803] {logging_mixin.py:115} INFO - [2023-02-24 23:02:45,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:02:49,114] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:02:49,115] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:02:49,115] {logging_mixin.py:115} INFO - here
[2023-02-24 23:02:49,141] {logging_mixin.py:115} INFO - [2023-02-24 23:02:49,135] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 23:02:49,142] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:02:49,211] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.423 seconds
[2023-02-24 23:03:20,076] {processor.py:153} INFO - Started process (PID=12548) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:03:20,079] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:03:20,081] {logging_mixin.py:115} INFO - [2023-02-24 23:03:20,081] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:03:24,317] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:03:24,324] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:03:24,326] {logging_mixin.py:115} INFO - here
[2023-02-24 23:03:24,406] {logging_mixin.py:115} INFO - [2023-02-24 23:03:24,395] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 23:03:24,409] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:03:24,577] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 4.514 seconds
[2023-02-24 23:03:54,869] {processor.py:153} INFO - Started process (PID=12615) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:03:54,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:03:54,873] {logging_mixin.py:115} INFO - [2023-02-24 23:03:54,873] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:03:57,992] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:03:57,993] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:03:57,994] {logging_mixin.py:115} INFO - here
[2023-02-24 23:03:58,018] {logging_mixin.py:115} INFO - [2023-02-24 23:03:58,013] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 23:03:58,019] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:03:58,068] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 3.208 seconds
[2023-02-24 23:04:28,828] {processor.py:153} INFO - Started process (PID=12681) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:04:28,832] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:04:28,833] {logging_mixin.py:115} INFO - [2023-02-24 23:04:28,833] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:04:31,695] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:04:31,696] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:04:31,700] {logging_mixin.py:115} INFO - here
[2023-02-24 23:04:31,730] {logging_mixin.py:115} INFO - [2023-02-24 23:04:31,726] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 200, in aws_extract_data_to_sqlite
    goes_files_available_list = get_all_geos_file_name_by_filter_new(station_goes, year, day_of_year, hour)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 56, in get_all_geos_file_name_by_filter_new
    for object_summary in src_bucket_goes.objects.filter(Prefix=  f'{station}/{year}/{day}/{hour}/'):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in create_request
    operation_name=operation_model.name,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/signers.py", line 189, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/auth.py", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2023-02-24 23:04:31,732] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:04:31,758] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 2.940 seconds
[2023-02-24 23:05:02,162] {processor.py:153} INFO - Started process (PID=12748) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:05:02,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:05:02,167] {logging_mixin.py:115} INFO - [2023-02-24 23:05:02,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:05:03,251] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:05:03,253] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:05:03,254] {logging_mixin.py:115} INFO - here
[2023-02-24 23:05:03,624] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:05:03,625] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:05:03,626] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:05:03,626] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:05:03,627] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:05:03,628] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:05:03,629] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:05:03,630] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:05:03,630] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:05:03,631] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:05:03,631] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:05:03,632] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:05:03,632] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:05:03,633] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:05:03,633] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:05:03,634] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:05:03,651] {logging_mixin.py:115} INFO - into create_table_nexrad
[2023-02-24 23:05:32,178] {logging_mixin.py:115} INFO - [2023-02-24 23:05:32,176] {timeout.py:67} ERROR - Process timed out, PID: 12748
[2023-02-24 23:05:32,191] {logging_mixin.py:115} INFO - [2023-02-24 23:05:32,182] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/httpsession.py", line 464, in send
    chunked=self._chunked(request.headers),
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/lib/python3.7/http/client.py", line 1373, in getresponse
    response.begin()
  File "/usr/local/lib/python3.7/http/client.py", line 319, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.7/http/client.py", line 280, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/ssl.py", line 1071, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.7/ssl.py", line 929, in read
    return self._sslobj.read(len, buffer)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/aws_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 12748

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 218, in aws_extract_data_to_sqlite
    noaa_filenames_available_list = get_all_nexrad_file_name_by_filter_new(year, month, date)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 38, in get_all_nexrad_file_name_by_filter_new
    for object_summary in src_bucket_noaa.objects.filter(Prefix=f'{year}/{month}/{date}/'): #/{month}/{day}/{station}
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 207, in _send_request
    exception,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 361, in _needs_retry
    request_dict=request_dict,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 207, in __call__
    if self._checker(**checker_kwargs):
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 285, in __call__
    attempt_number, response, caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 308, in _should_retry
    attempt_number, response, caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 364, in __call__
    attempt_number, response, caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 248, in __call__
    attempt_number, caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 416, in _check_caught_exception
    raise caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 281, in _do_get_response
    http_response = self._send(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 377, in _send
    return self.http_session.send(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/httpsession.py", line 500, in send
    raise HTTPClientError(error=e)
botocore.exceptions.HTTPClientError: An HTTP Client raised an unhandled exception: DagBag import timeout for /opt/airflow/dags/aws_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 12748
[2023-02-24 23:05:32,194] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:05:32,238] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 30.089 seconds
[2023-02-24 23:06:05,213] {processor.py:153} INFO - Started process (PID=12869) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:06:05,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:06:05,216] {logging_mixin.py:115} INFO - [2023-02-24 23:06:05,216] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:06:06,084] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:06:06,086] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:06:06,087] {logging_mixin.py:115} INFO - here
[2023-02-24 23:06:06,273] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:06:06,275] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:06:06,275] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:06:06,276] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:06:06,276] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:06:06,277] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:06:06,278] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:06:06,279] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:06:06,279] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:06:06,280] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:06:06,280] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:06:06,281] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:06:06,281] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:06:06,282] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:06:06,282] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:06:06,283] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:06:11,455] {logging_mixin.py:115} INFO - [2023-02-24 23:06:11,436] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:06:11,459] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:06:11,514] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.304 seconds
[2023-02-24 23:06:43,112] {processor.py:153} INFO - Started process (PID=12939) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:06:43,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:06:43,116] {logging_mixin.py:115} INFO - [2023-02-24 23:06:43,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:06:52,466] {logging_mixin.py:115} INFO - [2023-02-24 23:06:52,465] {process_utils.py:240} INFO - Waiting up to 5 seconds for processes to exit...
[2023-02-24 23:06:53,593] {logging_mixin.py:115} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0xffff96ca0cb0>
[2023-02-24 23:06:53,648] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2023-02-24 23:06:53,653] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/weakref.py", line 358, in remove
[2023-02-24 23:06:53,661] {logging_mixin.py:115} WARNING -     def remove(k, selfref=ref(self)):
[2023-02-24 23:06:53,664] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 458, in _exit_gracefully
[2023-02-24 23:06:53,673] {logging_mixin.py:115} WARNING -     self.end()
[2023-02-24 23:06:53,679] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 1119, in end
[2023-02-24 23:06:53,688] {logging_mixin.py:115} WARNING -     kill_child_processes_by_pids(pids_to_kill)
[2023-02-24 23:06:53,695] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/process_utils.py", line 240, in kill_child_processes_by_pids
[2023-02-24 23:06:53,713] {logging_mixin.py:115} WARNING -     log.info("Waiting up to %s seconds for processes to exit...", timeout)
[2023-02-24 23:06:53,716] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1378, in info
[2023-02-24 23:06:53,846] {logging_mixin.py:115} WARNING -     self._log(INFO, msg, args, **kwargs)
[2023-02-24 23:06:53,853] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1514, in _log
[2023-02-24 23:06:53,863] {logging_mixin.py:115} WARNING -     self.handle(record)
[2023-02-24 23:06:53,874] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1524, in handle
[2023-02-24 23:06:53,885] {logging_mixin.py:115} WARNING -     self.callHandlers(record)
[2023-02-24 23:06:53,892] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1586, in callHandlers
[2023-02-24 23:06:53,907] {logging_mixin.py:115} WARNING -     hdlr.handle(record)
[2023-02-24 23:06:53,916] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 894, in handle
[2023-02-24 23:06:53,929] {logging_mixin.py:115} WARNING -     self.emit(record)
[2023-02-24 23:06:53,952] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1028, in emit
[2023-02-24 23:06:53,975] {logging_mixin.py:115} WARNING -     stream.write(msg + self.terminator)
[2023-02-24 23:06:54,046] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/log/logging_mixin.py", line 127, in write
[2023-02-24 23:06:54,057] {logging_mixin.py:115} WARNING -     self.flush()
[2023-02-24 23:06:54,072] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/log/logging_mixin.py", line 134, in flush
[2023-02-24 23:06:54,082] {logging_mixin.py:115} WARNING -     self._propagate_log(buf)
[2023-02-24 23:06:54,099] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/log/logging_mixin.py", line 115, in _propagate_log
[2023-02-24 23:06:54,104] {logging_mixin.py:115} WARNING -     self.logger.log(self.level, remove_escape_codes(message))
[2023-02-24 23:06:54,110] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1444, in log
[2023-02-24 23:06:54,175] {logging_mixin.py:115} WARNING -     self._log(level, msg, args, **kwargs)
[2023-02-24 23:06:54,189] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1514, in _log
[2023-02-24 23:06:54,203] {logging_mixin.py:115} WARNING -     self.handle(record)
[2023-02-24 23:06:54,206] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1524, in handle
[2023-02-24 23:06:54,212] {logging_mixin.py:115} WARNING -     self.callHandlers(record)
[2023-02-24 23:06:54,216] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1586, in callHandlers
[2023-02-24 23:06:54,235] {logging_mixin.py:115} WARNING -     hdlr.handle(record)
[2023-02-24 23:06:54,272] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 894, in handle
[2023-02-24 23:06:54,332] {logging_mixin.py:115} WARNING -     self.emit(record)
[2023-02-24 23:06:54,361] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/log/file_processor_handler.py", line 68, in emit
[2023-02-24 23:06:54,386] {logging_mixin.py:115} WARNING -     self.handler.emit(record)
[2023-02-24 23:06:54,401] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1127, in emit
[2023-02-24 23:06:54,409] {logging_mixin.py:115} WARNING -     StreamHandler.emit(self, record)
[2023-02-24 23:06:54,417] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1029, in emit
[2023-02-24 23:06:54,426] {logging_mixin.py:115} WARNING -     self.flush()
[2023-02-24 23:06:54,431] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1009, in flush
[2023-02-24 23:06:54,435] {logging_mixin.py:115} WARNING -     self.stream.flush()
[2023-02-24 23:06:54,453] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 458, in _exit_gracefully
[2023-02-24 23:06:54,481] {logging_mixin.py:115} WARNING -     self.end()
[2023-02-24 23:06:54,503] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 1119, in end
[2023-02-24 23:06:54,511] {logging_mixin.py:115} WARNING -     kill_child_processes_by_pids(pids_to_kill)
[2023-02-24 23:06:54,513] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/process_utils.py", line 240, in kill_child_processes_by_pids
[2023-02-24 23:06:54,515] {logging_mixin.py:115} WARNING -     log.info("Waiting up to %s seconds for processes to exit...", timeout)
[2023-02-24 23:06:54,516] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1378, in info
[2023-02-24 23:06:54,528] {logging_mixin.py:115} WARNING -     self._log(INFO, msg, args, **kwargs)
[2023-02-24 23:06:54,531] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1514, in _log
[2023-02-24 23:06:54,541] {logging_mixin.py:115} WARNING -     self.handle(record)
[2023-02-24 23:06:54,551] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 1524, in handle
[2023-02-24 23:06:54,567] {logging_mixin.py:115} WARNING -     self.callHandlers(record)
[2023-02-24 23:07:47,492] {processor.py:153} INFO - Started process (PID=44) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:07:47,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:07:47,503] {logging_mixin.py:115} INFO - [2023-02-24 23:07:47,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:07:51,825] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:07:51,827] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:07:51,827] {logging_mixin.py:115} INFO - here
[2023-02-24 23:07:52,271] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:07:52,274] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:07:52,275] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:07:52,276] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:07:52,276] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:07:52,277] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:07:52,278] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:07:52,278] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:07:52,279] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:07:52,279] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:07:52,280] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:07:52,281] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:07:52,281] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:07:52,282] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:07:52,283] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:07:52,283] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:07:57,932] {logging_mixin.py:115} INFO - [2023-02-24 23:07:57,852] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:07:57,940] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:07:58,090] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 10.605 seconds
[2023-02-24 23:08:47,325] {processor.py:153} INFO - Started process (PID=110) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:08:47,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:08:47,328] {logging_mixin.py:115} INFO - [2023-02-24 23:08:47,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:08:48,160] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:08:48,161] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:08:48,161] {logging_mixin.py:115} INFO - here
[2023-02-24 23:08:48,351] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:08:48,353] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:08:48,354] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:08:48,355] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:08:48,356] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:08:48,358] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:08:48,359] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:08:48,360] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:08:48,361] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:08:48,363] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:08:48,364] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:08:48,365] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:08:48,366] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:08:48,367] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:08:48,367] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:08:48,368] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:08:53,744] {logging_mixin.py:115} INFO - [2023-02-24 23:08:53,727] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:08:53,752] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:08:53,873] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.553 seconds
[2023-02-24 23:09:24,974] {processor.py:153} INFO - Started process (PID=174) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:09:24,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:09:24,979] {logging_mixin.py:115} INFO - [2023-02-24 23:09:24,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:09:25,908] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:09:25,909] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:09:25,910] {logging_mixin.py:115} INFO - here
[2023-02-24 23:09:26,104] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:09:26,105] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552306175_e20230552308548_c20230552308578.nc
[2023-02-24 23:09:26,106] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:09:26,107] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552306175_e20230552308548_c20230552308568.nc
[2023-02-24 23:09:26,108] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:09:26,108] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552306175_e20230552308548_c20230552308580.nc
[2023-02-24 23:09:26,109] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:09:26,111] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552306175_e20230552308548_c20230552308573.nc
[2023-02-24 23:09:26,112] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:09:26,112] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552306175_e20230552308548_c20230552308577.nc
[2023-02-24 23:09:26,113] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:09:26,113] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552306175_e20230552308553_c20230552308584.nc
[2023-02-24 23:09:26,114] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:09:26,114] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552306175_e20230552308559_c20230552308591.nc
[2023-02-24 23:09:26,115] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:09:26,115] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552306175_e20230552308548_c20230552309003.nc
[2023-02-24 23:09:26,116] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:09:26,116] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552306175_e20230552308553_c20230552309010.nc
[2023-02-24 23:09:26,117] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:09:26,117] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552306175_e20230552308559_c20230552308588.nc
[2023-02-24 23:09:26,118] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:09:26,118] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552306175_e20230552308548_c20230552308594.nc
[2023-02-24 23:09:26,119] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:09:26,120] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552306175_e20230552308553_c20230552309007.nc
[2023-02-24 23:09:26,121] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:09:26,121] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552306175_e20230552308559_c20230552308597.nc
[2023-02-24 23:09:26,122] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:09:26,122] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552306175_e20230552308548_c20230552309000.nc
[2023-02-24 23:09:26,123] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:09:26,123] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552306175_e20230552308553_c20230552309005.nc
[2023-02-24 23:09:26,124] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:09:26,124] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552306175_e20230552308559_c20230552308587.nc
[2023-02-24 23:09:31,275] {logging_mixin.py:115} INFO - [2023-02-24 23:09:31,264] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:09:31,277] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:09:31,346] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.394 seconds
[2023-02-24 23:10:02,432] {processor.py:153} INFO - Started process (PID=249) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:10:02,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:10:02,438] {logging_mixin.py:115} INFO - [2023-02-24 23:10:02,437] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:10:03,587] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:10:03,588] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:10:03,589] {logging_mixin.py:115} INFO - here
[2023-02-24 23:10:03,812] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:10:03,814] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552306175_e20230552308548_c20230552308578.nc
[2023-02-24 23:10:03,814] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:10:03,815] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552306175_e20230552308548_c20230552308568.nc
[2023-02-24 23:10:03,816] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:10:03,817] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552306175_e20230552308548_c20230552308580.nc
[2023-02-24 23:10:03,817] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:10:03,819] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552306175_e20230552308548_c20230552308573.nc
[2023-02-24 23:10:03,820] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:10:03,820] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552306175_e20230552308548_c20230552308577.nc
[2023-02-24 23:10:03,821] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:10:03,821] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552306175_e20230552308553_c20230552308584.nc
[2023-02-24 23:10:03,822] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:10:03,823] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552306175_e20230552308559_c20230552308591.nc
[2023-02-24 23:10:03,826] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:10:03,827] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552306175_e20230552308548_c20230552309003.nc
[2023-02-24 23:10:03,827] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:10:03,828] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552306175_e20230552308553_c20230552309010.nc
[2023-02-24 23:10:03,829] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:10:03,829] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552306175_e20230552308559_c20230552308588.nc
[2023-02-24 23:10:03,831] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:10:03,832] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552306175_e20230552308548_c20230552308594.nc
[2023-02-24 23:10:03,833] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:10:03,834] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552306175_e20230552308553_c20230552309007.nc
[2023-02-24 23:10:03,835] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:10:03,836] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552306175_e20230552308559_c20230552308597.nc
[2023-02-24 23:10:03,837] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:10:03,838] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552306175_e20230552308548_c20230552309000.nc
[2023-02-24 23:10:03,839] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:10:03,840] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552306175_e20230552308553_c20230552309005.nc
[2023-02-24 23:10:03,841] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:10:03,843] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552306175_e20230552308559_c20230552308587.nc
[2023-02-24 23:10:09,036] {logging_mixin.py:115} INFO - [2023-02-24 23:10:09,019] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:10:09,043] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:10:09,124] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.709 seconds
[2023-02-24 23:10:39,316] {processor.py:153} INFO - Started process (PID=313) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:10:39,319] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:10:39,320] {logging_mixin.py:115} INFO - [2023-02-24 23:10:39,320] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:10:41,109] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:10:41,111] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:10:41,113] {logging_mixin.py:115} INFO - here
[2023-02-24 23:10:41,717] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:10:41,723] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552306175_e20230552308548_c20230552308578.nc
[2023-02-24 23:10:41,724] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:10:41,726] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552306175_e20230552308548_c20230552308568.nc
[2023-02-24 23:10:41,727] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:10:41,728] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552306175_e20230552308548_c20230552308580.nc
[2023-02-24 23:10:41,729] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:10:41,730] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552306175_e20230552308548_c20230552308573.nc
[2023-02-24 23:10:41,731] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:10:41,732] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552306175_e20230552308548_c20230552308577.nc
[2023-02-24 23:10:41,733] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:10:41,733] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552306175_e20230552308553_c20230552308584.nc
[2023-02-24 23:10:41,734] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:10:41,735] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552306175_e20230552308559_c20230552308591.nc
[2023-02-24 23:10:41,736] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:10:41,736] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552306175_e20230552308548_c20230552309003.nc
[2023-02-24 23:10:41,737] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:10:41,738] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552306175_e20230552308553_c20230552309010.nc
[2023-02-24 23:10:41,739] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:10:41,739] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552306175_e20230552308559_c20230552308588.nc
[2023-02-24 23:10:41,740] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:10:41,740] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552306175_e20230552308548_c20230552308594.nc
[2023-02-24 23:10:41,741] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:10:41,742] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552306175_e20230552308553_c20230552309007.nc
[2023-02-24 23:10:41,743] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:10:41,744] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552306175_e20230552308559_c20230552308597.nc
[2023-02-24 23:10:41,744] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:10:41,745] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552306175_e20230552308548_c20230552309000.nc
[2023-02-24 23:10:41,747] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:10:41,748] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552306175_e20230552308553_c20230552309005.nc
[2023-02-24 23:10:41,749] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:10:41,750] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552306175_e20230552308559_c20230552308587.nc
[2023-02-24 23:10:46,981] {logging_mixin.py:115} INFO - [2023-02-24 23:10:46,971] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:10:46,983] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:10:47,062] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 7.754 seconds
[2023-02-24 23:11:17,749] {processor.py:153} INFO - Started process (PID=379) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:11:17,751] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:11:17,753] {logging_mixin.py:115} INFO - [2023-02-24 23:11:17,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:11:18,998] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:11:19,000] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:11:19,001] {logging_mixin.py:115} INFO - here
[2023-02-24 23:11:20,066] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:11:20,068] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552306175_e20230552308548_c20230552308578.nc
[2023-02-24 23:11:20,069] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:11:20,070] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552306175_e20230552308548_c20230552308568.nc
[2023-02-24 23:11:20,071] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:11:20,072] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552306175_e20230552308548_c20230552308580.nc
[2023-02-24 23:11:20,073] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:11:20,075] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552306175_e20230552308548_c20230552308573.nc
[2023-02-24 23:11:20,076] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:11:20,082] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552306175_e20230552308548_c20230552308577.nc
[2023-02-24 23:11:20,084] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:11:20,087] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552306175_e20230552308553_c20230552308584.nc
[2023-02-24 23:11:20,088] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:11:20,088] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552306175_e20230552308559_c20230552308591.nc
[2023-02-24 23:11:20,089] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:11:20,090] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552306175_e20230552308548_c20230552309003.nc
[2023-02-24 23:11:20,090] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:11:20,091] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552306175_e20230552308553_c20230552309010.nc
[2023-02-24 23:11:20,092] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:11:20,093] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552306175_e20230552308559_c20230552308588.nc
[2023-02-24 23:11:20,093] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:11:20,094] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552306175_e20230552308548_c20230552308594.nc
[2023-02-24 23:11:20,094] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:11:20,095] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552306175_e20230552308553_c20230552309007.nc
[2023-02-24 23:11:20,095] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:11:20,096] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552306175_e20230552308559_c20230552308597.nc
[2023-02-24 23:11:20,096] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:11:20,096] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552306175_e20230552308548_c20230552309000.nc
[2023-02-24 23:11:20,097] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:11:20,097] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552306175_e20230552308553_c20230552309005.nc
[2023-02-24 23:11:20,098] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:11:20,098] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552306175_e20230552308559_c20230552308587.nc
[2023-02-24 23:11:25,317] {logging_mixin.py:115} INFO - [2023-02-24 23:11:25,308] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:11:25,320] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:11:25,382] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 7.642 seconds
[2023-02-24 23:11:55,880] {processor.py:153} INFO - Started process (PID=444) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:11:55,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:11:55,884] {logging_mixin.py:115} INFO - [2023-02-24 23:11:55,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:11:56,795] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:11:56,796] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:11:56,796] {logging_mixin.py:115} INFO - here
[2023-02-24 23:11:57,309] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:11:57,311] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552306175_e20230552308548_c20230552308578.nc
[2023-02-24 23:11:57,313] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:11:57,314] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552306175_e20230552308548_c20230552308568.nc
[2023-02-24 23:11:57,315] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:11:57,316] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552306175_e20230552308548_c20230552308580.nc
[2023-02-24 23:11:57,318] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:11:57,319] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552306175_e20230552308548_c20230552308573.nc
[2023-02-24 23:11:57,320] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:11:57,321] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552306175_e20230552308548_c20230552308577.nc
[2023-02-24 23:11:57,322] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:11:57,323] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552306175_e20230552308553_c20230552308584.nc
[2023-02-24 23:11:57,324] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:11:57,325] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552306175_e20230552308559_c20230552308591.nc
[2023-02-24 23:11:57,326] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:11:57,326] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552306175_e20230552308548_c20230552309003.nc
[2023-02-24 23:11:57,327] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:11:57,329] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552306175_e20230552308553_c20230552309010.nc
[2023-02-24 23:11:57,330] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:11:57,330] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552306175_e20230552308559_c20230552308588.nc
[2023-02-24 23:11:57,331] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:11:57,333] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552306175_e20230552308548_c20230552308594.nc
[2023-02-24 23:11:57,334] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:11:57,335] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552306175_e20230552308553_c20230552309007.nc
[2023-02-24 23:11:57,336] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:11:57,337] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552306175_e20230552308559_c20230552308597.nc
[2023-02-24 23:11:57,337] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:11:57,338] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552306175_e20230552308548_c20230552309000.nc
[2023-02-24 23:11:57,339] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:11:57,339] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552306175_e20230552308553_c20230552309005.nc
[2023-02-24 23:11:57,340] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:11:57,341] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552306175_e20230552308559_c20230552308587.nc
[2023-02-24 23:12:02,544] {logging_mixin.py:115} INFO - [2023-02-24 23:12:02,536] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:12:02,547] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:12:02,589] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.723 seconds
[2023-02-24 23:12:33,538] {processor.py:153} INFO - Started process (PID=515) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:12:33,542] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:12:33,547] {logging_mixin.py:115} INFO - [2023-02-24 23:12:33,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:12:34,458] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:12:34,459] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:12:34,460] {logging_mixin.py:115} INFO - here
[2023-02-24 23:12:35,149] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:12:35,162] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552306175_e20230552308548_c20230552308578.nc
[2023-02-24 23:12:35,162] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:12:35,163] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552306175_e20230552308548_c20230552308568.nc
[2023-02-24 23:12:35,164] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:12:35,164] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552306175_e20230552308548_c20230552308580.nc
[2023-02-24 23:12:35,165] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:12:35,166] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552306175_e20230552308548_c20230552308573.nc
[2023-02-24 23:12:35,166] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:12:35,167] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552306175_e20230552308548_c20230552308577.nc
[2023-02-24 23:12:35,168] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:12:35,168] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552306175_e20230552308553_c20230552308584.nc
[2023-02-24 23:12:35,169] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:12:35,169] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552306175_e20230552308559_c20230552308591.nc
[2023-02-24 23:12:35,170] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:12:35,170] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552306175_e20230552308548_c20230552309003.nc
[2023-02-24 23:12:35,171] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:12:35,171] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552306175_e20230552308553_c20230552309010.nc
[2023-02-24 23:12:35,172] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:12:35,172] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552306175_e20230552308559_c20230552308588.nc
[2023-02-24 23:12:35,173] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:12:35,173] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552306175_e20230552308548_c20230552308594.nc
[2023-02-24 23:12:35,174] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:12:35,174] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552306175_e20230552308553_c20230552309007.nc
[2023-02-24 23:12:35,175] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:12:35,175] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552306175_e20230552308559_c20230552308597.nc
[2023-02-24 23:12:35,176] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:12:35,176] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552306175_e20230552308548_c20230552309000.nc
[2023-02-24 23:12:35,177] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:12:35,177] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552306175_e20230552308553_c20230552309005.nc
[2023-02-24 23:12:35,178] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:12:35,178] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552306175_e20230552308559_c20230552308587.nc
[2023-02-24 23:12:39,455] {logging_mixin.py:115} INFO - into create_table_nexrad
[2023-02-24 23:13:03,560] {logging_mixin.py:115} INFO - [2023-02-24 23:13:03,559] {timeout.py:67} ERROR - Process timed out, PID: 515
[2023-02-24 23:13:03,575] {logging_mixin.py:115} INFO - [2023-02-24 23:13:03,563] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/httpsession.py", line 464, in send
    chunked=self._chunked(request.headers),
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/lib/python3.7/http/client.py", line 1373, in getresponse
    response.begin()
  File "/usr/local/lib/python3.7/http/client.py", line 319, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.7/http/client.py", line 280, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/ssl.py", line 1071, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.7/ssl.py", line 929, in read
    return self._sslobj.read(len, buffer)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/aws_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 515

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 218, in aws_extract_data_to_sqlite
    noaa_filenames_available_list = get_all_nexrad_file_name_by_filter_new(year, month, date)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 38, in get_all_nexrad_file_name_by_filter_new
    for object_summary in src_bucket_noaa.objects.filter(Prefix=f'{year}/{month}/{date}/'): #/{month}/{day}/{station}
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 81, in __iter__
    for page in self.pages():
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/resources/collection.py", line 171, in pages
    for page in pages:
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/paginate.py", line 357, in _make_request
    return self._method(**current_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 944, in _make_api_call
    operation_model, request_dict, request_context
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 966, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 207, in _send_request
    exception,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 361, in _needs_retry
    request_dict=request_dict,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 207, in __call__
    if self._checker(**checker_kwargs):
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 285, in __call__
    attempt_number, response, caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 308, in _should_retry
    attempt_number, response, caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 364, in __call__
    attempt_number, response, caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 248, in __call__
    attempt_number, caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 416, in _check_caught_exception
    raise caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 281, in _do_get_response
    http_response = self._send(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 377, in _send
    return self.http_session.send(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/httpsession.py", line 500, in send
    raise HTTPClientError(error=e)
botocore.exceptions.HTTPClientError: An HTTP Client raised an unhandled exception: DagBag import timeout for /opt/airflow/dags/aws_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 515
[2023-02-24 23:13:03,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:13:03,604] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 30.081 seconds
[2023-02-24 23:13:34,407] {processor.py:153} INFO - Started process (PID=629) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:13:34,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:13:34,411] {logging_mixin.py:115} INFO - [2023-02-24 23:13:34,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:13:35,337] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:13:35,339] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:13:35,339] {logging_mixin.py:115} INFO - here
[2023-02-24 23:13:35,680] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:13:35,682] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552306175_e20230552308548_c20230552308578.nc
[2023-02-24 23:13:35,683] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:13:35,683] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552306175_e20230552308548_c20230552308568.nc
[2023-02-24 23:13:35,684] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:13:35,685] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552306175_e20230552308548_c20230552308580.nc
[2023-02-24 23:13:35,686] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:13:35,687] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552306175_e20230552308548_c20230552308573.nc
[2023-02-24 23:13:35,688] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:13:35,689] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552306175_e20230552308548_c20230552308577.nc
[2023-02-24 23:13:35,690] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:13:35,690] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552306175_e20230552308553_c20230552308584.nc
[2023-02-24 23:13:35,691] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:13:35,692] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552306175_e20230552308559_c20230552308591.nc
[2023-02-24 23:13:35,692] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:13:35,693] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552306175_e20230552308548_c20230552309003.nc
[2023-02-24 23:13:35,693] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:13:35,694] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552306175_e20230552308553_c20230552309010.nc
[2023-02-24 23:13:35,695] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:13:35,696] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552306175_e20230552308559_c20230552308588.nc
[2023-02-24 23:13:35,697] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:13:35,698] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552306175_e20230552308548_c20230552308594.nc
[2023-02-24 23:13:35,699] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:13:35,699] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552306175_e20230552308553_c20230552309007.nc
[2023-02-24 23:13:35,700] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:13:35,701] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552306175_e20230552308559_c20230552308597.nc
[2023-02-24 23:13:35,702] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:13:35,705] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552306175_e20230552308548_c20230552309000.nc
[2023-02-24 23:13:35,708] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:13:35,709] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552306175_e20230552308553_c20230552309005.nc
[2023-02-24 23:13:35,710] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:13:35,711] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552306175_e20230552308559_c20230552308587.nc
[2023-02-24 23:13:41,074] {logging_mixin.py:115} INFO - [2023-02-24 23:13:41,066] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:13:41,087] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:13:41,156] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.755 seconds
[2023-02-24 23:14:12,102] {processor.py:153} INFO - Started process (PID=692) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:14:12,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:14:12,105] {logging_mixin.py:115} INFO - [2023-02-24 23:14:12,105] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:14:13,031] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:14:13,033] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:14:13,035] {logging_mixin.py:115} INFO - here
[2023-02-24 23:14:13,440] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:14:13,442] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552306175_e20230552308548_c20230552308578.nc
[2023-02-24 23:14:13,443] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:14:13,444] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552306175_e20230552308548_c20230552308568.nc
[2023-02-24 23:14:13,445] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:14:13,446] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552306175_e20230552308548_c20230552308580.nc
[2023-02-24 23:14:13,447] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:14:13,447] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552306175_e20230552308548_c20230552308573.nc
[2023-02-24 23:14:13,448] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552311175_e20230552313548_c20230552313564.nc
[2023-02-24 23:14:13,448] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:14:13,449] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552306175_e20230552308548_c20230552308577.nc
[2023-02-24 23:14:13,450] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:14:13,450] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552306175_e20230552308553_c20230552308584.nc
[2023-02-24 23:14:13,451] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552311175_e20230552313554_c20230552313569.nc
[2023-02-24 23:14:13,451] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:14:13,452] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552306175_e20230552308559_c20230552308591.nc
[2023-02-24 23:14:13,452] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:14:13,453] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552306175_e20230552308548_c20230552309003.nc
[2023-02-24 23:14:13,453] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:14:13,454] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552306175_e20230552308553_c20230552309010.nc
[2023-02-24 23:14:13,455] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:14:13,455] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552306175_e20230552308559_c20230552308588.nc
[2023-02-24 23:14:13,456] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:14:13,457] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552306175_e20230552308548_c20230552308594.nc
[2023-02-24 23:14:13,458] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:14:13,458] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552306175_e20230552308553_c20230552309007.nc
[2023-02-24 23:14:13,459] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:14:13,460] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552306175_e20230552308559_c20230552308597.nc
[2023-02-24 23:14:13,460] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:14:13,461] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552306175_e20230552308548_c20230552309000.nc
[2023-02-24 23:14:13,462] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:14:13,462] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552306175_e20230552308553_c20230552309005.nc
[2023-02-24 23:14:13,463] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:14:13,463] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552306175_e20230552308559_c20230552308587.nc
[2023-02-24 23:14:18,646] {logging_mixin.py:115} INFO - [2023-02-24 23:14:18,629] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    aws_extract_data_to_sqlite()
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    metadata_instance.insert_data_into_goes(station_goes, year, day_of_year,hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:14:18,653] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:14:18,709] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 6.613 seconds
[2023-02-24 23:14:49,185] {processor.py:153} INFO - Started process (PID=758) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:14:49,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:14:49,191] {logging_mixin.py:115} INFO - [2023-02-24 23:14:49,191] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:14:50,561] {logging_mixin.py:115} INFO - into create_table_goes
[2023-02-24 23:14:50,562] {logging_mixin.py:115} INFO - todays 24 02 2023 23 055
[2023-02-24 23:14:50,563] {logging_mixin.py:115} INFO - here
[2023-02-24 23:14:50,898] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552301175_e20230552303548_c20230552303580.nc
[2023-02-24 23:14:50,899] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552306175_e20230552308548_c20230552308578.nc
[2023-02-24 23:14:50,900] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C01_G18_s20230552311175_e20230552313548_c20230552313580.nc
[2023-02-24 23:14:50,901] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552301175_e20230552303548_c20230552303567.nc
[2023-02-24 23:14:50,902] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552306175_e20230552308548_c20230552308568.nc
[2023-02-24 23:14:50,902] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C02_G18_s20230552311175_e20230552313548_c20230552313567.nc
[2023-02-24 23:14:50,904] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552301175_e20230552303548_c20230552303577.nc
[2023-02-24 23:14:50,905] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552306175_e20230552308548_c20230552308580.nc
[2023-02-24 23:14:50,905] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C03_G18_s20230552311175_e20230552313548_c20230552313578.nc
[2023-02-24 23:14:50,906] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552301175_e20230552303548_c20230552303584.nc
[2023-02-24 23:14:50,907] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552306175_e20230552308548_c20230552308573.nc
[2023-02-24 23:14:50,907] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C04_G18_s20230552311175_e20230552313548_c20230552313564.nc
[2023-02-24 23:14:50,908] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552301175_e20230552303548_c20230552303573.nc
[2023-02-24 23:14:50,908] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552306175_e20230552308548_c20230552308577.nc
[2023-02-24 23:14:50,909] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C05_G18_s20230552311175_e20230552313548_c20230552313575.nc
[2023-02-24 23:14:50,909] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552301175_e20230552303553_c20230552303587.nc
[2023-02-24 23:14:50,910] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552306175_e20230552308553_c20230552308584.nc
[2023-02-24 23:14:50,910] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C06_G18_s20230552311175_e20230552313554_c20230552313569.nc
[2023-02-24 23:14:50,911] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552301175_e20230552303559_c20230552304008.nc
[2023-02-24 23:14:50,911] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552306175_e20230552308559_c20230552308591.nc
[2023-02-24 23:14:50,912] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C07_G18_s20230552311175_e20230552313559_c20230552313589.nc
[2023-02-24 23:14:50,913] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552301175_e20230552303548_c20230552304012.nc
[2023-02-24 23:14:50,913] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552306175_e20230552308548_c20230552309003.nc
[2023-02-24 23:14:50,914] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C08_G18_s20230552311175_e20230552313548_c20230552313591.nc
[2023-02-24 23:14:50,915] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552301175_e20230552303553_c20230552303589.nc
[2023-02-24 23:14:50,916] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552306175_e20230552308553_c20230552309010.nc
[2023-02-24 23:14:50,916] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C09_G18_s20230552311175_e20230552313553_c20230552313598.nc
[2023-02-24 23:14:50,917] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552301175_e20230552303559_c20230552303596.nc
[2023-02-24 23:14:50,918] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552306175_e20230552308559_c20230552308588.nc
[2023-02-24 23:14:50,918] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C10_G18_s20230552311175_e20230552313559_c20230552313594.nc
[2023-02-24 23:14:50,919] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552301175_e20230552303548_c20230552304004.nc
[2023-02-24 23:14:50,920] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552306175_e20230552308548_c20230552308594.nc
[2023-02-24 23:14:50,920] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C11_G18_s20230552311175_e20230552313548_c20230552314002.nc
[2023-02-24 23:14:50,921] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552301175_e20230552303553_c20230552304000.nc
[2023-02-24 23:14:50,922] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552306175_e20230552308553_c20230552309007.nc
[2023-02-24 23:14:50,923] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C12_G18_s20230552311175_e20230552313554_c20230552314006.nc
[2023-02-24 23:14:50,924] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552301175_e20230552303559_c20230552303592.nc
[2023-02-24 23:14:50,926] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552306175_e20230552308559_c20230552308597.nc
[2023-02-24 23:14:50,927] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C13_G18_s20230552311175_e20230552313559_c20230552313583.nc
[2023-02-24 23:14:50,928] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552301175_e20230552303548_c20230552303594.nc
[2023-02-24 23:14:50,929] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552306175_e20230552308548_c20230552309000.nc
[2023-02-24 23:14:50,929] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C14_G18_s20230552311175_e20230552313548_c20230552314004.nc
[2023-02-24 23:14:50,930] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552301175_e20230552303553_c20230552304016.nc
[2023-02-24 23:14:50,931] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552306175_e20230552308553_c20230552309005.nc
[2023-02-24 23:14:50,931] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C15_G18_s20230552311175_e20230552313553_c20230552314008.nc
[2023-02-24 23:14:50,932] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552301175_e20230552303559_c20230552304005.nc
[2023-02-24 23:14:50,932] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552306175_e20230552308559_c20230552308587.nc
[2023-02-24 23:14:50,933] {logging_mixin.py:115} INFO - OR_ABI-L1b-RadC-M6C16_G18_s20230552311175_e20230552313559_c20230552313596.nc
[2023-02-24 23:14:56,149] {logging_mixin.py:115} INFO - [2023-02-24 23:14:56,129] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 8, in <module>
    from sql_aws_metadata import aws_extract_data_to_sqlite, populate_database
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 251, in <module>
    # %%
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 206, in aws_extract_data_to_sqlite
    # metadata_instance.insert_data_into_goes(station_goes, year, day_of_year, hour, filename)
  File "/opt/airflow/plugins/sql_aws_metadata.py", line 129, in insert_data_into_goes
    self.cursor.execute(insert_str)
sqlite3.OperationalError: database is locked
[2023-02-24 23:14:56,156] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:14:56,248] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 7.068 seconds
[2023-02-24 23:15:38,931] {processor.py:153} INFO - Started process (PID=834) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:15:38,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:15:38,934] {logging_mixin.py:115} INFO - [2023-02-24 23:15:38,933] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:15:39,697] {logging_mixin.py:115} INFO - [2023-02-24 23:15:39,694] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 96, in <module>
    sleep_process >> aws_to_sql_extraction_process >> database_populate
NameError: name 'database_populate' is not defined
[2023-02-24 23:15:39,698] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:15:39,727] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.800 seconds
[2023-02-24 23:16:10,806] {processor.py:153} INFO - Started process (PID=900) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:16:10,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:16:10,810] {logging_mixin.py:115} INFO - [2023-02-24 23:16:10,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:16:11,596] {logging_mixin.py:115} INFO - [2023-02-24 23:16:11,594] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/aws_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/aws_dag.py", line 96, in <module>
    sleep_process >> aws_to_sql_extraction_process >> database_populate
NameError: name 'database_populate' is not defined
[2023-02-24 23:16:11,597] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:16:11,619] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 0.819 seconds
[2023-02-24 23:16:39,612] {processor.py:153} INFO - Started process (PID=940) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:16:39,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:16:39,617] {logging_mixin.py:115} INFO - [2023-02-24 23:16:39,617] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:16:40,854] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:16:41,118] {logging_mixin.py:115} INFO - [2023-02-24 23:16:41,115] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 23:16:41,173] {logging_mixin.py:115} INFO - [2023-02-24 23:16:41,173] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T23:10:00+00:00, run_after=2023-02-24T23:15:00+00:00
[2023-02-24 23:16:41,221] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.620 seconds
[2023-02-24 23:17:11,929] {processor.py:153} INFO - Started process (PID=1006) to work on /opt/airflow/dags/aws_dag.py
[2023-02-24 23:17:11,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/aws_dag.py for tasks to queue
[2023-02-24 23:17:11,936] {logging_mixin.py:115} INFO - [2023-02-24 23:17:11,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:17:13,519] {processor.py:651} INFO - DAG(s) dict_keys(['aws_extract_dag']) retrieved from /opt/airflow/dags/aws_dag.py
[2023-02-24 23:17:13,602] {logging_mixin.py:115} INFO - [2023-02-24 23:17:13,601] {dag.py:2371} INFO - Sync 1 DAGs
[2023-02-24 23:17:13,673] {logging_mixin.py:115} INFO - [2023-02-24 23:17:13,673] {dag.py:2919} INFO - Setting next_dagrun for aws_extract_dag to 2023-02-24T23:15:00+00:00, run_after=2023-02-24T23:20:00+00:00
[2023-02-24 23:17:13,774] {processor.py:161} INFO - Processing /opt/airflow/dags/aws_dag.py took 1.887 seconds
